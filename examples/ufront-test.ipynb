{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f098a07",
   "metadata": {
    "papermill": {
     "duration": 0.012733,
     "end_time": "2024-05-23T03:30:28.109533",
     "exception": false,
     "start_time": "2024-05-23T03:30:28.096800",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ImageNet inference with UFront"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73050cee",
   "metadata": {
    "papermill": {
     "duration": 0.011159,
     "end_time": "2024-05-23T03:30:28.132868",
     "exception": false,
     "start_time": "2024-05-23T03:30:28.121709",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### You may also run this jupyter notebook on Kaggle (anonymous repo): \n",
    "#### https://www.kaggle.com/code/anomyuser/ufront-test/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dc482ed",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-23T03:30:28.156234Z",
     "iopub.status.busy": "2024-05-23T03:30:28.155866Z",
     "iopub.status.idle": "2024-05-23T03:30:35.448712Z",
     "shell.execute_reply": "2024-05-23T03:30:35.447704Z"
    },
    "papermill": {
     "duration": 7.307615,
     "end_time": "2024-05-23T03:30:35.451141",
     "exception": false,
     "start_time": "2024-05-23T03:30:28.143526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch,os,random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Tuple\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils import data\n",
    "from functools import partial\n",
    "from torchvision.models import resnet18, resnet50, squeezenet1_1, regnet_x_32gf, maxvit_t, shufflenet_v2_x1_5, inception_v3, mobilenet_v3_small, efficientnet_v2_s, densenet121, convnext_small\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5db7f973",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T03:30:35.476464Z",
     "iopub.status.busy": "2024-05-23T03:30:35.475802Z",
     "iopub.status.idle": "2024-05-23T03:30:36.434660Z",
     "shell.execute_reply": "2024-05-23T03:30:36.433648Z"
    },
    "papermill": {
     "duration": 0.974138,
     "end_time": "2024-05-23T03:30:36.436847",
     "exception": false,
     "start_time": "2024-05-23T03:30:35.462709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.13\r\n"
     ]
    }
   ],
   "source": [
    "# check python first\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ebc753",
   "metadata": {
    "papermill": {
     "duration": 0.010838,
     "end_time": "2024-05-23T03:30:36.460041",
     "exception": false,
     "start_time": "2024-05-23T03:30:36.449203",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Prepare the ImageNet validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0b6d1a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T03:30:36.484764Z",
     "iopub.status.busy": "2024-05-23T03:30:36.483991Z",
     "iopub.status.idle": "2024-05-23T03:30:37.645744Z",
     "shell.execute_reply": "2024-05-23T03:30:37.644690Z"
    },
    "papermill": {
     "duration": 1.176172,
     "end_time": "2024-05-23T03:30:37.647757",
     "exception": false,
     "start_time": "2024-05-23T03:30:36.471585",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-05-23 03:30:37--  https://raw.githubusercontent.com/raghakot/keras-vis/master/resources/imagenet_class_index.json\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 35363 (35K) [text/plain]\r\n",
      "Saving to: 'imagenet_class_index.json'\r\n",
      "\r\n",
      "imagenet_class_inde 100%[===================>]  34.53K  --.-KB/s    in 0.01s   \r\n",
      "\r\n",
      "2024-05-23 03:30:37 (3.38 MB/s) - 'imagenet_class_index.json' saved [35363/35363]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "root = \"/kaggle/input/\" #set to the path of imagenet-1k validation set, which contains a folder named 'imagenet1kvalid'\n",
    "working = \"/kaggle/working/\"\n",
    "!wget https://raw.githubusercontent.com/raghakot/keras-vis/master/resources/imagenet_class_index.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2fcb366",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T03:30:37.671876Z",
     "iopub.status.busy": "2024-05-23T03:30:37.671585Z",
     "iopub.status.idle": "2024-05-23T03:30:37.685239Z",
     "shell.execute_reply": "2024-05-23T03:30:37.684363Z"
    },
    "papermill": {
     "duration": 0.028295,
     "end_time": "2024-05-23T03:30:37.687285",
     "exception": false,
     "start_time": "2024-05-23T03:30:37.658990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import json\n",
    "syn_to_class = {}\n",
    "with open(os.path.join(working, \"imagenet_class_index.json\"), \"rb\") as f:\n",
    "    json_file = json.load(f)\n",
    "    for class_id, v in json_file.items():\n",
    "        syn_to_class[class_id] = v[1]\n",
    "                \n",
    "def get_class_name(entry):        \n",
    "    target = syn_to_class[int(entry)]\n",
    "    return target\n",
    "        \n",
    "class ImageNetKaggle(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.samples = []\n",
    "        self.targets = []\n",
    "        self.transform = transform\n",
    "        samples_dir = os.path.join(root, \"imagenet1kvalid\")\n",
    "        for entry in os.listdir(samples_dir):\n",
    "                sample_path = os.path.join(samples_dir, entry)\n",
    "                for file in os.listdir(sample_path):                    \n",
    "                    self.samples.append(os.path.join(sample_path, file))\n",
    "                    self.targets.append(int(entry))\n",
    "                \n",
    "    def __len__(self):\n",
    "            return len(self.samples)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "            x = Image.open(self.samples[idx]).convert(\"RGB\")\n",
    "            if self.transform:\n",
    "                x = self.transform(x)\n",
    "            return x, self.targets[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b44888",
   "metadata": {
    "papermill": {
     "duration": 0.0111,
     "end_time": "2024-05-23T03:30:37.709463",
     "exception": false,
     "start_time": "2024-05-23T03:30:37.698363",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Prepare Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e62103a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T03:30:37.732413Z",
     "iopub.status.busy": "2024-05-23T03:30:37.732138Z",
     "iopub.status.idle": "2024-05-23T03:30:54.163089Z",
     "shell.execute_reply": "2024-05-23T03:30:54.162034Z"
    },
    "papermill": {
     "duration": 16.444913,
     "end_time": "2024-05-23T03:30:54.165280",
     "exception": false,
     "start_time": "2024-05-23T03:30:37.720367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "val_transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize(256),\n",
    "                transforms.CenterCrop(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean, std),\n",
    "            ]\n",
    "        )\n",
    "dataset = ImageNetKaggle(root, val_transform)\n",
    "dataloader = DataLoader(\n",
    "            dataset,\n",
    "            batch_size=64, # may need to reduce this depending on your GPU \n",
    "            num_workers=8, # may need to reduce this depending on your num of CPUs and RAM\n",
    "            shuffle=False,\n",
    "            drop_last=False,\n",
    "            pin_memory=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441ded42",
   "metadata": {
    "papermill": {
     "duration": 0.011232,
     "end_time": "2024-05-23T03:30:54.187831",
     "exception": false,
     "start_time": "2024-05-23T03:30:54.176599",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1) Download and install UFront package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47063623",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T03:30:54.212157Z",
     "iopub.status.busy": "2024-05-23T03:30:54.211789Z",
     "iopub.status.idle": "2024-05-23T03:31:02.419899Z",
     "shell.execute_reply": "2024-05-23T03:31:02.418740Z"
    },
    "papermill": {
     "duration": 8.222763,
     "end_time": "2024-05-23T03:31:02.422097",
     "exception": false,
     "start_time": "2024-05-23T03:30:54.199334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-05-23 03:30:55--  https://anonymous.4open.science/r/anonyufront-2B3E/release/ufront-0.1.1-cp310-cp310-manylinux_2_28_x86_64.whl\r\n",
      "Resolving anonymous.4open.science (anonymous.4open.science)... 172.67.183.76, 104.21.18.195, 2606:4700:3035::ac43:b74c, ...\r\n",
      "Connecting to anonymous.4open.science (anonymous.4open.science)|172.67.183.76|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: /api/repo/anonyufront-2B3E/file/release/ufront-0.1.1-cp310-cp310-manylinux_2_28_x86_64.whl [following]\r\n",
      "--2024-05-23 03:30:55--  https://anonymous.4open.science/api/repo/anonyufront-2B3E/file/release/ufront-0.1.1-cp310-cp310-manylinux_2_28_x86_64.whl\r\n",
      "Reusing existing connection to anonymous.4open.science:443.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: unspecified [application/octet-stream]\r\n",
      "Saving to: 'ufront-0.1.1-cp310-cp310-manylinux_2_28_x86_64.whl'\r\n",
      "\r\n",
      "ufront-0.1.1-cp310-     [      <=>           ]  57.79M  9.64MB/s    in 6.5s    \r\n",
      "\r\n",
      "2024-05-23 03:31:02 (8.87 MB/s) - 'ufront-0.1.1-cp310-cp310-manylinux_2_28_x86_64.whl' saved [60595669]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# You may execute !python --version and install the following ufront package based on your python version\n",
    "# You may download the latest UFront package or obtain them from the release folder\n",
    "\n",
    "# For Python 3.7\n",
    "# !wget https://anonymous.4open.science/r/anonyufront-2B3E/release/ufront-0.1.1-cp37-cp37m-manylinux_2_28_x86_64.whl\n",
    "\n",
    "# For Python 3.8\n",
    "# !wget https://anonymous.4open.science/r/anonyufront-2B3E/release/ufront-0.1.1-cp38-cp38-manylinux_2_28_x86_64.whl\n",
    "\n",
    "# For Python 3.9\n",
    "# !wget https://anonymous.4open.science/r/anonyufront-2B3E/release/ufront-0.1.1-cp39-cp39-manylinux_2_28_x86_64.whl\n",
    "\n",
    "# For Python 3.10\n",
    "!wget https://anonymous.4open.science/r/anonyufront-2B3E/release/ufront-0.1.1-cp310-cp310-manylinux_2_28_x86_64.whl\n",
    "\n",
    "# For Python 3.11\n",
    "# !wget https://anonymous.4open.science/r/anonyufront-2B3E/release/ufront-0.1.1-cp311-cp311-manylinux_2_28_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "229db35c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T03:31:02.481299Z",
     "iopub.status.busy": "2024-05-23T03:31:02.480567Z",
     "iopub.status.idle": "2024-05-23T03:31:19.139410Z",
     "shell.execute_reply": "2024-05-23T03:31:19.138366Z"
    },
    "papermill": {
     "duration": 16.677981,
     "end_time": "2024-05-23T03:31:19.141780",
     "exception": false,
     "start_time": "2024-05-23T03:31:02.463799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./ufront-0.1.1-cp310-cp310-manylinux_2_28_x86_64.whl\r\n",
      "Requirement already satisfied: onnx in /opt/conda/lib/python3.10/site-packages (from ufront==0.1.1) (1.16.0)\r\n",
      "Collecting tf2onnx (from ufront==0.1.1)\r\n",
      "  Downloading tf2onnx-1.16.1-py3-none-any.whl.metadata (1.3 kB)\r\n",
      "Collecting onnxsim==0.4.17 (from ufront==0.1.1)\r\n",
      "  Downloading onnxsim-0.4.17-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\r\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from onnxsim==0.4.17->ufront==0.1.1) (13.7.0)\r\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.10/site-packages (from onnx->ufront==0.1.1) (1.26.4)\r\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /opt/conda/lib/python3.10/site-packages (from onnx->ufront==0.1.1) (3.20.3)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from tf2onnx->ufront==0.1.1) (2.31.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from tf2onnx->ufront==0.1.1) (1.16.0)\r\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /opt/conda/lib/python3.10/site-packages (from tf2onnx->ufront==0.1.1) (23.5.26)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->tf2onnx->ufront==0.1.1) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->tf2onnx->ufront==0.1.1) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->tf2onnx->ufront==0.1.1) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->tf2onnx->ufront==0.1.1) (2024.2.2)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->onnxsim==0.4.17->ufront==0.1.1) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->onnxsim==0.4.17->ufront==0.1.1) (2.17.2)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->onnxsim==0.4.17->ufront==0.1.1) (0.1.2)\r\n",
      "Downloading onnxsim-0.4.17-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tf2onnx-1.16.1-py3-none-any.whl (455 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m455.8/455.8 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: tf2onnx, onnxsim, ufront\r\n",
      "Successfully installed onnxsim-0.4.17 tf2onnx-1.16.1 ufront-0.1.1\r\n"
     ]
    }
   ],
   "source": [
    "# !pip install ufront-0.1.1-cp37-cp37m-manylinux_2_28_x86_64.whl #for python3.7\n",
    "\n",
    "# !pip install ufront-0.1.1-cp38-cp38-manylinux_2_28_x86_64.whl #for python3.8\n",
    "# !pip install ufront-0.1.1-cp39-cp39-manylinux_2_28_x86_64.whl #for python3.9\n",
    "!pip install ufront-0.1.1-cp310-cp310-manylinux_2_28_x86_64.whl #for python3.10\n",
    "# !pip install ufront-0.1.1-cp311-cp311-manylinux_2_28_x86_64.whl #for python3.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26c2ddb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T03:31:19.175346Z",
     "iopub.status.busy": "2024-05-23T03:31:19.174538Z",
     "iopub.status.idle": "2024-05-23T03:31:20.224615Z",
     "shell.execute_reply": "2024-05-23T03:31:20.223439Z"
    },
    "papermill": {
     "duration": 1.069566,
     "end_time": "2024-05-23T03:31:20.227145",
     "exception": false,
     "start_time": "2024-05-23T03:31:19.157579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu May 23 03:31:20 2024       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\r\n",
      "| N/A   38C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   1  Tesla T4                       Off | 00000000:00:05.0 Off |                    0 |\r\n",
      "| N/A   33C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|  No running processes found                                                           |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95a521d",
   "metadata": {
    "papermill": {
     "duration": 0.015312,
     "end_time": "2024-05-23T03:31:20.258747",
     "exception": false,
     "start_time": "2024-05-23T03:31:20.243435",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 2) Install compiler backend and runtime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "953f66c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T03:31:20.290887Z",
     "iopub.status.busy": "2024-05-23T03:31:20.290515Z",
     "iopub.status.idle": "2024-05-23T03:31:36.380737Z",
     "shell.execute_reply": "2024-05-23T03:31:36.379442Z"
    },
    "papermill": {
     "duration": 16.109601,
     "end_time": "2024-05-23T03:31:36.383340",
     "exception": false,
     "start_time": "2024-05-23T03:31:20.273739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting iree-compiler==20230815.614\r\n",
      "  Downloading iree_compiler-20230815.614-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (577 bytes)\r\n",
      "Collecting iree-runtime==20230815.614\r\n",
      "  Downloading iree_runtime-20230815.614-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from iree-compiler==20230815.614) (1.26.4)\r\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from iree-compiler==20230815.614) (6.0.1)\r\n",
      "Downloading iree_compiler-20230815.614-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (68.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.2/68.2 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading iree_runtime-20230815.614-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: iree-runtime, iree-compiler\r\n",
      "Successfully installed iree-compiler-20230815.614 iree-runtime-20230815.614\r\n"
     ]
    }
   ],
   "source": [
    "# !pip install iree-compiler==20231004.665 iree-runtime==20231004.665\n",
    "!pip install iree-compiler==20230815.614 iree-runtime==20230815.614\n",
    "# !pip install iree-tools-tf==20230815.614  iree-tools-tflite==20230815.614"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97df7e0b",
   "metadata": {
    "papermill": {
     "duration": 0.017775,
     "end_time": "2024-05-23T03:31:36.419762",
     "exception": false,
     "start_time": "2024-05-23T03:31:36.401987",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 3) Compile the models and run compiled models on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce998968",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T03:31:36.457273Z",
     "iopub.status.busy": "2024-05-23T03:31:36.456926Z",
     "iopub.status.idle": "2024-05-23T03:31:50.350002Z",
     "shell.execute_reply": "2024-05-23T03:31:50.349162Z"
    },
    "papermill": {
     "duration": 13.914619,
     "end_time": "2024-05-23T03:31:50.352337",
     "exception": false,
     "start_time": "2024-05-23T03:31:36.437718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Installing onnxruntime by `/opt/conda/bin/python -m pip install --user onnxruntime`, please wait for a moment..</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mInstalling onnxruntime by `/opt/conda/bin/python -m pip install --user onnxruntime`, please wait for a moment..\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onnxruntime\n",
      "  Downloading onnxruntime-1.18.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.3 kB)\n",
      "Collecting coloredlogs (from onnxruntime)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime) (23.5.26)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /opt/conda/lib/python3.10/site-packages (from onnxruntime) (1.26.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from onnxruntime) (21.3)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from onnxruntime) (3.20.3)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from onnxruntime) (1.12)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->onnxruntime) (3.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->onnxruntime) (1.3.0)\n",
      "Downloading onnxruntime-1.18.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m  WARNING: The script humanfriendly is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script coloredlogs is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script onnxruntime_test is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.18.0\n"
     ]
    }
   ],
   "source": [
    "from ufront.pytorch.model import UFrontTorch \n",
    "import iree\n",
    "import iree.compiler as ireec\n",
    "from iree.compiler import tools\n",
    "from iree import runtime\n",
    "\n",
    "def get_ufront_ir(net, dataloader):\n",
    "    for x, y in dataloader:\n",
    "        break\n",
    "    net.eval()\n",
    "    indata = x.numpy()\n",
    "    print(\"Compiling model...\")\n",
    "    model = UFrontTorch(net, batch_size=indata.shape[0], pass_weights=True) # convert torch model to ufront model\n",
    "    #This will trigger Rust frontend for actual model conversion and graph building\n",
    "    #operators can also be managed by python side (each operator here corresponding to an operator in the Rust computation graph)\n",
    "    output_tensors = model(inputs = [indata])\n",
    "\n",
    "    #The output of the model (forward pass have not been triggered at the moment!)\n",
    "    output = model.softmax(input=output_tensors[0], name=\"softmax_out\")\n",
    "\n",
    "    #This will trigger model compilation, i.e., convert Rust computation graph to a unified high-level IR and lower it to TOSA IR\n",
    "    model.compile(optimizer={\"type\":\"sgd\", \"lr\":\"0.01\", \"momentum\":\"0\", \"nesterov\":\"False\", \"weight_decay\":\"0\"},\n",
    "                        loss='sparse_categorical_crossentropy', metrics=['accuracy', 'sparse_categorical_crossentropy'])\n",
    "    \n",
    "    modelir = model.dump_ir()\n",
    "    return modelir\n",
    "\n",
    "def compile_with_ufront(net, GPU, dataloader):\n",
    "    for x, y in dataloader:\n",
    "        break\n",
    "    net.eval()\n",
    "    indata = x.numpy()\n",
    "    print(\"Compiling model...\")\n",
    "    model = UFrontTorch(net, batch_size=indata.shape[0], pass_weights=True) # convert torch model to ufront model\n",
    "    #This will trigger Rust frontend for actual model conversion and graph building\n",
    "    #operators can also be managed by python side (each operator here corresponding to an operator in the Rust computation graph)\n",
    "    output_tensors = model(inputs = [indata])\n",
    "\n",
    "    #The output of the model (forward pass have not been triggered at the moment!)\n",
    "    output = model.softmax(input=output_tensors[0], name=\"softmax_out\")\n",
    "\n",
    "    #This will trigger model compilation, i.e., convert Rust computation graph to a unified high-level IR and lower it to TOSA IR\n",
    "    model.compile(optimizer={\"type\":\"sgd\", \"lr\":\"0.01\", \"momentum\":\"0\", \"nesterov\":\"False\", \"weight_decay\":\"0\"},\n",
    "                        loss='sparse_categorical_crossentropy', metrics=['accuracy', 'sparse_categorical_crossentropy'])\n",
    "    \n",
    "    modelir = model.dump_ir()\n",
    "    \n",
    "    print(\"Compiling to TOSA...\")\n",
    "    tosa_ir= model.dump_tosa_ir()\n",
    "\n",
    "    print(\"Compiling to binary...\")\n",
    "    if GPU:\n",
    "        binary = ireec.compile_str(tosa_ir,\n",
    "                        target_backends=[\"cuda\"], \n",
    "                        input_type=ireec.InputType.TOSA)\n",
    "        module = runtime.load_vm_flatbuffer(binary, driver=\"cuda\")\n",
    "    else:\n",
    "        binary = ireec.compile_str(tosa_ir,\n",
    "                        target_backends=[\"llvm-cpu\"], \n",
    "                        input_type=ireec.InputType.TOSA)\n",
    "        module = runtime.load_vm_flatbuffer(binary,backend=\"llvm-cpu\") \n",
    "    print(\"binary executable produced!\")\n",
    "    return module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fa6ca02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T03:31:50.392347Z",
     "iopub.status.busy": "2024-05-23T03:31:50.392031Z",
     "iopub.status.idle": "2024-05-23T03:31:50.398803Z",
     "shell.execute_reply": "2024-05-23T03:31:50.397896Z"
    },
    "papermill": {
     "duration": 0.028865,
     "end_time": "2024-05-23T03:31:50.400793",
     "exception": false,
     "start_time": "2024-05-23T03:31:50.371928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_ufront_accuracy(module, dataloader):\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    batch_size = 0\n",
    "    print(\"Start inference...\")\n",
    "    for x, y in tqdm(dataloader):\n",
    "        if batch_size == 0:\n",
    "            batch_size = x.shape[0]\n",
    "        elif x.shape[0] < batch_size:\n",
    "            print(\"Ignore last batch!\") #dynamic batch size is currently not supported!\n",
    "            break\n",
    "        y_pred = module.forward(x.numpy()).to_host()\n",
    "        correct += (y_pred.argmax(axis=1) == y.numpy()).sum().item()\n",
    "        total += len(y)\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c23c0771",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T03:31:50.439676Z",
     "iopub.status.busy": "2024-05-23T03:31:50.439132Z",
     "iopub.status.idle": "2024-05-23T03:31:50.444236Z",
     "shell.execute_reply": "2024-05-23T03:31:50.443380Z"
    },
    "papermill": {
     "duration": 0.026563,
     "end_time": "2024-05-23T03:31:50.446118",
     "exception": false,
     "start_time": "2024-05-23T03:31:50.419555",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#If you experiencing the following error, you need to upgrade NVidia Driver and CUDA; or you can lower IREE to a lower version, e.g., 20230330.474.\n",
    "\n",
    "#RuntimeError: Error creating vm context with modules: \n",
    "#main_checkout/runtime/src/iree/hal/drivers/cuda/native_executable.c:99: INTERNAL; \n",
    "#CUDA driver error 'CUDA_ERROR_UNSUPPORTED_PTX_VERSION' (222): \n",
    "#the provided PTX was compiled with an unsupported toolchain.; \n",
    "#while invoking native function hal.executable.create; while calling import; "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0928dd17",
   "metadata": {
    "papermill": {
     "duration": 0.018491,
     "end_time": "2024-05-23T03:31:50.483791",
     "exception": false,
     "start_time": "2024-05-23T03:31:50.465300",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Compile Vision models and perform inference on ImageNet validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08b2f5a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T03:31:50.522862Z",
     "iopub.status.busy": "2024-05-23T03:31:50.522173Z",
     "iopub.status.idle": "2024-05-23T03:34:26.301652Z",
     "shell.execute_reply": "2024-05-23T03:34:26.299837Z"
    },
    "papermill": {
     "duration": 155.801414,
     "end_time": "2024-05-23T03:34:26.303829",
     "exception": false,
     "start_time": "2024-05-23T03:31:50.502415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_small-047dcff4.pth\n",
      "100%|██████████| 9.83M/9.83M [00:00<00:00, 74.3MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/overrides.py:110: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'\n",
      "  torch.has_cuda,\n",
      "/opt/conda/lib/python3.10/site-packages/torch/overrides.py:111: UserWarning: 'has_cudnn' is deprecated, please use 'torch.backends.cudnn.is_available()'\n",
      "  torch.has_cudnn,\n",
      "/opt/conda/lib/python3.10/site-packages/torch/overrides.py:117: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  torch.has_mps,\n",
      "/opt/conda/lib/python3.10/site-packages/torch/overrides.py:118: UserWarning: 'has_mkldnn' is deprecated, please use 'torch.backends.mkldnn.is_available()'\n",
      "  torch.has_mkldnn,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling to TOSA...\n",
      "Compiling to binary...\n",
      "binary executable produced!\n",
      "Start inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 781/782 [02:19<00:00,  5.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignore last batch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6700544174135723"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = mobilenet_v3_small(weights=\"DEFAULT\", dropout=0.0)\n",
    "module = compile_with_ufront(net, True, dataloader) # compile to binary\n",
    "get_ufront_accuracy(module, dataloader) # inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc7116db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T03:34:26.409933Z",
     "iopub.status.busy": "2024-05-23T03:34:26.409168Z",
     "iopub.status.idle": "2024-05-23T03:36:54.676658Z",
     "shell.execute_reply": "2024-05-23T03:36:54.675527Z"
    },
    "papermill": {
     "duration": 148.322346,
     "end_time": "2024-05-23T03:36:54.678942",
     "exception": false,
     "start_time": "2024-05-23T03:34:26.356596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/shufflenetv2_x1_5-3c479a10.pth\" to /root/.cache/torch/hub/checkpoints/shufflenetv2_x1_5-3c479a10.pth\n",
      "100%|██████████| 13.6M/13.6M [00:00<00:00, 68.7MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model...\n",
      "Compiling to TOSA...\n",
      "Compiling to binary...\n",
      "binary executable produced!\n",
      "Start inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 781/782 [02:15<00:00,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignore last batch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7154089308578745"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = shufflenet_v2_x1_5(weights=\"DEFAULT\")\n",
    "module = compile_with_ufront(net, True, dataloader)\n",
    "get_ufront_accuracy(module, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbb23c92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T03:36:54.905834Z",
     "iopub.status.busy": "2024-05-23T03:36:54.905475Z",
     "iopub.status.idle": "2024-05-23T03:39:20.873204Z",
     "shell.execute_reply": "2024-05-23T03:39:20.871738Z"
    },
    "papermill": {
     "duration": 146.084005,
     "end_time": "2024-05-23T03:39:20.876511",
     "exception": false,
     "start_time": "2024-05-23T03:36:54.792506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/squeezenet1_1-b8a52dc0.pth\" to /root/.cache/torch/hub/checkpoints/squeezenet1_1-b8a52dc0.pth\n",
      "100%|██████████| 4.73M/4.73M [00:00<00:00, 46.9MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model...\n",
      "Compiling to TOSA...\n",
      "Compiling to binary...\n",
      "binary executable produced!\n",
      "Start inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 781/782 [02:17<00:00,  5.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignore last batch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5783650768245838"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = squeezenet1_1(weights=\"DEFAULT\")\n",
    "module = compile_with_ufront(net, True, dataloader)\n",
    "get_ufront_accuracy(module, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ee1320a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T03:39:21.237867Z",
     "iopub.status.busy": "2024-05-23T03:39:21.237473Z",
     "iopub.status.idle": "2024-05-23T03:44:09.525941Z",
     "shell.execute_reply": "2024-05-23T03:44:09.524010Z"
    },
    "papermill": {
     "duration": 288.471405,
     "end_time": "2024-05-23T03:44:09.528082",
     "exception": false,
     "start_time": "2024-05-23T03:39:21.056677",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 126MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model...\n",
      "Compiling to TOSA...\n",
      "Compiling to binary...\n",
      "binary executable produced!\n",
      "Start inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 781/782 [04:37<00:00,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignore last batch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6934018886043534"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = resnet18(weights=\"DEFAULT\")\n",
    "module = compile_with_ufront(net, True, dataloader)\n",
    "get_ufront_accuracy(module, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c850ad92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T03:44:10.011217Z",
     "iopub.status.busy": "2024-05-23T03:44:10.010255Z",
     "iopub.status.idle": "2024-05-23T03:53:54.394242Z",
     "shell.execute_reply": "2024-05-23T03:53:54.392922Z"
    },
    "papermill": {
     "duration": 584.62921,
     "end_time": "2024-05-23T03:53:54.396339",
     "exception": false,
     "start_time": "2024-05-23T03:44:09.767129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
      "100%|██████████| 97.8M/97.8M [00:00<00:00, 154MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model...\n",
      "Compiling to TOSA...\n",
      "Compiling to binary...\n",
      "binary executable produced!\n",
      "Start inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 781/782 [09:24<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignore last batch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7921334827144686"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = resnet50(weights=\"DEFAULT\")\n",
    "module = compile_with_ufront(net, True, dataloader)\n",
    "get_ufront_accuracy(module, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1a9b637",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T03:53:55.011812Z",
     "iopub.status.busy": "2024-05-23T03:53:55.010771Z",
     "iopub.status.idle": "2024-05-23T04:01:37.160481Z",
     "shell.execute_reply": "2024-05-23T04:01:37.159514Z"
    },
    "papermill": {
     "duration": 462.454229,
     "end_time": "2024-05-23T04:01:37.162612",
     "exception": false,
     "start_time": "2024-05-23T03:53:54.708383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n",
      "100%|██████████| 30.8M/30.8M [00:00<00:00, 118MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model...\n",
      "Compiling to TOSA...\n",
      "Compiling to binary...\n",
      "binary executable produced!\n",
      "Start inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 781/782 [06:09<00:00,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignore last batch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7347751280409731"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = densenet121(weights=\"DEFAULT\")\n",
    "module = compile_with_ufront(net, True, dataloader)\n",
    "get_ufront_accuracy(module, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8eba62d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T04:01:37.901337Z",
     "iopub.status.busy": "2024-05-23T04:01:37.900959Z",
     "iopub.status.idle": "2024-05-23T04:08:38.263491Z",
     "shell.execute_reply": "2024-05-23T04:08:38.262318Z"
    },
    "papermill": {
     "duration": 420.732277,
     "end_time": "2024-05-23T04:08:38.265391",
     "exception": false,
     "start_time": "2024-05-23T04:01:37.533114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n",
      "100%|██████████| 104M/104M [00:00<00:00, 144MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model...\n",
      "Compiling to TOSA...\n",
      "Compiling to binary...\n",
      "binary executable produced!\n",
      "Start inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 781/782 [06:30<00:00,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignore last batch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6995038412291933"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = inception_v3(weights=\"DEFAULT\") \n",
    "module = compile_with_ufront(net, True, dataloader)\n",
    "get_ufront_accuracy(module, dataloader) #low performance than official reported, to fix this, the image size need to resize to 299 x 299, instead of standard 224 x 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74385557",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T04:08:39.173141Z",
     "iopub.status.busy": "2024-05-23T04:08:39.172315Z",
     "iopub.status.idle": "2024-05-23T04:23:49.309024Z",
     "shell.execute_reply": "2024-05-23T04:23:49.307817Z"
    },
    "papermill": {
     "duration": 911.018101,
     "end_time": "2024-05-23T04:23:49.768513",
     "exception": false,
     "start_time": "2024-05-23T04:08:38.750412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vit_b_16-c867db91.pth\" to /root/.cache/torch/hub/checkpoints/vit_b_16-c867db91.pth\n",
      "100%|██████████| 330M/330M [00:02<00:00, 164MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model...\n",
      "Compiling to TOSA...\n",
      "Compiling to binary...\n",
      "binary executable produced!\n",
      "Start inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 781/782 [14:43<00:01,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignore last batch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8054577464788732"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "net = models.vision_transformer.vit_b_16(weights=\"DEFAULT\")\n",
    "module = compile_with_ufront(net, True, dataloader)\n",
    "get_ufront_accuracy(module, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1841c54e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T04:23:50.768862Z",
     "iopub.status.busy": "2024-05-23T04:23:50.768014Z",
     "iopub.status.idle": "2024-05-23T04:40:59.710029Z",
     "shell.execute_reply": "2024-05-23T04:40:59.708707Z"
    },
    "papermill": {
     "duration": 1029.44702,
     "end_time": "2024-05-23T04:40:59.711932",
     "exception": false,
     "start_time": "2024-05-23T04:23:50.264912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model...\n",
      "Compiling to TOSA...\n",
      "Compiling to binary...\n",
      "binary executable produced!\n",
      "Start inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 781/782 [16:39<00:01,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignore last batch!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7689660691421255"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fix low performance of inception3\n",
    "val_transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize(299),\n",
    "                transforms.CenterCrop(299), #299 instead of 224, see this: https://github.com/IntelLabs/distiller/issues/422\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean, std),\n",
    "            ]\n",
    "        )\n",
    "dataset = ImageNetKaggle(root, val_transform)\n",
    "dataloader = DataLoader(\n",
    "            dataset,\n",
    "            batch_size=64, # may need to reduce this depending on your GPU \n",
    "            num_workers=8, # may need to reduce this depending on your num of CPUs and RAM\n",
    "            shuffle=False,\n",
    "            drop_last=False,\n",
    "            pin_memory=True\n",
    "        )\n",
    "net = inception_v3(weights=\"DEFAULT\") \n",
    "module = compile_with_ufront(net, True, dataloader)\n",
    "get_ufront_accuracy(module, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29ca0651",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T04:41:00.843892Z",
     "iopub.status.busy": "2024-05-23T04:41:00.843503Z",
     "iopub.status.idle": "2024-05-23T04:41:01.519936Z",
     "shell.execute_reply": "2024-05-23T04:41:01.518818Z"
    },
    "papermill": {
     "duration": 1.249601,
     "end_time": "2024-05-23T04:41:01.522836",
     "exception": false,
     "start_time": "2024-05-23T04:41:00.273235",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize(299),\n",
    "                transforms.CenterCrop(224), #299 instead of 224, see this: https://github.com/IntelLabs/distiller/issues/422\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean, std),\n",
    "            ]\n",
    "        )\n",
    "dataset = ImageNetKaggle(root, val_transform)\n",
    "dataloader = DataLoader(\n",
    "            dataset,\n",
    "            batch_size=64, # may need to reduce this depending on your GPU \n",
    "            num_workers=8, # may need to reduce this depending on your num of CPUs and RAM\n",
    "            shuffle=False,\n",
    "            drop_last=False,\n",
    "            pin_memory=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9c29ca",
   "metadata": {
    "papermill": {
     "duration": 0.623632,
     "end_time": "2024-05-23T04:41:02.721711",
     "exception": false,
     "start_time": "2024-05-23T04:41:02.098079",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### You may also print high-level of Vision Transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ddf3166f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T04:41:03.851383Z",
     "iopub.status.busy": "2024-05-23T04:41:03.851030Z",
     "iopub.status.idle": "2024-05-23T04:41:09.656832Z",
     "shell.execute_reply": "2024-05-23T04:41:09.655697Z"
    },
    "papermill": {
     "duration": 6.374177,
     "end_time": "2024-05-23T04:41:09.659182",
     "exception": false,
     "start_time": "2024-05-23T04:41:03.285005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model...\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "net = models.vision_transformer.vit_b_16(weights=\"DEFAULT\")\n",
    "ir = get_ufront_ir(net, dataloader)\n",
    "# print(ir) # enable this to see high-level IR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd22ea3",
   "metadata": {
    "papermill": {
     "duration": 0.566389,
     "end_time": "2024-05-23T04:41:10.844709",
     "exception": false,
     "start_time": "2024-05-23T04:41:10.278320",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Bert Model Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5f7639",
   "metadata": {},
   "source": [
    "### Compile and run the Bert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da125ba7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T04:41:18.964787Z",
     "iopub.status.busy": "2024-05-23T04:41:18.963566Z",
     "iopub.status.idle": "2024-05-23T04:41:38.655268Z",
     "shell.execute_reply": "2024-05-23T04:41:38.654175Z"
    },
    "papermill": {
     "duration": 20.255352,
     "end_time": "2024-05-23T04:41:38.657571",
     "exception": false,
     "start_time": "2024-05-23T04:41:18.402219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling TOSA model...\n",
      "Compiling Binary...\n",
      "[[[-0.0126075   1.4139326  -0.91023034 ...  0.28366825  0.08602214\n",
      "   -0.23005815]\n",
      "  [-0.542039    3.2243483  -0.38521275 ...  0.6640264  -0.24791919\n",
      "    0.73075116]\n",
      "  [-0.72975683  0.75377995 -0.5804731  ... -0.6268702   0.17821047\n",
      "    0.5281703 ]]\n",
      "\n",
      " [[-1.6963978   2.2013307  -2.1347208  ...  1.3283901   0.01012164\n",
      "    0.93355817]\n",
      "  [-0.13298714  1.5196626  -0.9118973  ...  0.44733378  0.096411\n",
      "    0.09232111]\n",
      "  [-1.90262     2.535816   -1.4880081  ...  1.140133   -0.42023683\n",
      "   -0.19271582]]]\n",
      "[[-0.23113337 -0.76582193 -0.87582827 ... -0.282242   -0.4502077\n",
      "   0.14065129]\n",
      " [ 0.3177823  -0.7155069  -0.8724887  ... -0.59379053  0.13726538\n",
      "  -0.04291175]]\n",
      "(<IREE DeviceArray: shape=[2, 3, 768], dtype=float32>, <IREE DeviceArray: shape=[2, 768], dtype=float32>)\n"
     ]
    }
   ],
   "source": [
    "from ufront.pytorch.model import UFrontTorch \n",
    "import iree.compiler as ireec\n",
    "from iree import runtime\n",
    "from torch_bert import BertModel, BertConfig\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "GPU = True\n",
    "\n",
    "#sampel input defined in pytorch-pretrained-bert\n",
    "input_ids = torch.from_numpy(np.array([[31, 51, 99], [15, 5, 0]], dtype=\"int32\"))\n",
    "input_mask = torch.from_numpy(np.array([[1, 1, 1], [1, 1, 0]], dtype=\"int32\"))\n",
    "token_type_ids = torch.from_numpy(np.array([[0, 0, 1], [0, 1, 0]], dtype=\"int32\"))\n",
    "\n",
    "config = BertConfig(vocab_size_or_config_json_file=16000, hidden_size=768,\n",
    "    num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072)\n",
    "\n",
    "net = BertModel(config=config)\n",
    "net.eval()\n",
    "\n",
    "model = UFrontTorch(net, batch_size=1, pass_weights=True) # convert torch model to ufront model\n",
    "\n",
    "output_tensors = model(inputs = [input_ids, token_type_ids, input_mask])\n",
    "\n",
    "#This will trigger model compilation, i.e., convert Rust computation graph to a unified high-level IR and lower it to TOSA IR\n",
    "model.compile(optimizer={\"type\":\"sgd\", \"lr\":\"0.01\", \"momentum\":\"0\", \"nesterov\":\"False\", \"weight_decay\":\"0\"},\n",
    "                    loss='sparse_categorical_crossentropy', metrics=['accuracy', 'sparse_categorical_crossentropy'])\n",
    "\n",
    "modelir = model.dump_ir()\n",
    "\n",
    "\n",
    "print(\"Compiling TOSA model...\")\n",
    "tosa_ir= model.dump_tosa_ir()\n",
    "\n",
    "print(\"Compiling Binary...\")\n",
    "\n",
    "if GPU:\n",
    "    binary = ireec.compile_str(tosa_ir,\n",
    "                    target_backends=[\"cuda\"], \n",
    "                    input_type=ireec.InputType.TOSA)\n",
    "    module = runtime.load_vm_flatbuffer(binary, driver=\"cuda\")\n",
    "else:\n",
    "    binary = ireec.compile_str(tosa_ir,\n",
    "                    target_backends=[\"llvm-cpu\"], \n",
    "                    input_type=ireec.InputType.TOSA)\n",
    "    module = runtime.load_vm_flatbuffer(binary,backend=\"llvm-cpu\") \n",
    "\n",
    "ufront_ret = module.forward(input_ids, token_type_ids, input_mask)\n",
    "for ret in ufront_ret:\n",
    "    print(ret.to_host())\n",
    "\n",
    "print(ufront_ret)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf8dad09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T04:41:39.864137Z",
     "iopub.status.busy": "2024-05-23T04:41:39.863287Z",
     "iopub.status.idle": "2024-05-23T04:41:39.994931Z",
     "shell.execute_reply": "2024-05-23T04:41:39.993589Z"
    },
    "papermill": {
     "duration": 0.710359,
     "end_time": "2024-05-23T04:41:39.997538",
     "exception": false,
     "start_time": "2024-05-23T04:41:39.287179",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.01260887  1.4139341  -0.9102301  ...  0.28366798  0.08602166\n",
      "   -0.23005718]\n",
      "  [-0.54203975  3.2243488  -0.38521317 ...  0.6640283  -0.24792111\n",
      "    0.73075086]\n",
      "  [-0.72975695  0.7537807  -0.5804765  ... -0.6268691   0.17821254\n",
      "    0.5281709 ]]\n",
      "\n",
      " [[-1.6963985   2.2013319  -2.13472    ...  1.3283904   0.01012149\n",
      "    0.933557  ]\n",
      "  [-0.13299099  1.5196633  -0.9118963  ...  0.4473327   0.09641235\n",
      "    0.09232146]\n",
      "  [-1.9026217   2.5358202  -1.4880085  ...  1.1401304  -0.42023662\n",
      "   -0.1927179 ]]]\n",
      "[[-0.23113278 -0.76582175 -0.875828   ... -0.28224295 -0.45020658\n",
      "   0.14065078]\n",
      " [ 0.3177829  -0.7155074  -0.8724886  ... -0.59379     0.1372653\n",
      "  -0.04291317]]\n"
     ]
    }
   ],
   "source": [
    "torch_ret = net(input_ids, token_type_ids, input_mask)\n",
    "for ret in torch_ret:\n",
    "    print(ret.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3550cd7",
   "metadata": {
    "papermill": {
     "duration": 0.622391,
     "end_time": "2024-05-23T04:41:41.201764",
     "exception": false,
     "start_time": "2024-05-23T04:41:40.579373",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Results comparison (UFront vs Pytorch output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df798e29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T04:41:42.348041Z",
     "iopub.status.busy": "2024-05-23T04:41:42.347111Z",
     "iopub.status.idle": "2024-05-23T04:41:42.354433Z",
     "shell.execute_reply": "2024-05-23T04:41:42.353541Z"
    },
    "papermill": {
     "duration": 0.568964,
     "end_time": "2024-05-23T04:41:42.356573",
     "exception": false,
     "start_time": "2024-05-23T04:41:41.787609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mse(y_true, y_pred):\n",
    "    return torch.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return torch.sqrt(mse(y_true, y_pred))\n",
    "\n",
    "def mae(y_true, y_pred):\n",
    "    return torch.mean(torch.abs(y_true - y_pred))\n",
    "\n",
    "# also known as cod\n",
    "def r_square(y_true, y_pred):\n",
    "    y_mean = torch.mean(y_true)\n",
    "    ss_tot = torch.sum((y_true - y_mean) ** 2)\n",
    "    ss_res = torch.sum((y_true - y_pred) ** 2)\n",
    "    return 1 - ss_res / ss_tot\n",
    "\n",
    "def mpe(y_true, y_pred):\n",
    "    return torch.mean((y_true - y_pred) / y_true) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "50b8a168",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T04:41:43.471353Z",
     "iopub.status.busy": "2024-05-23T04:41:43.470395Z",
     "iopub.status.idle": "2024-05-23T04:41:43.487028Z",
     "shell.execute_reply": "2024-05-23T04:41:43.485910Z"
    },
    "papermill": {
     "duration": 0.581331,
     "end_time": "2024-05-23T04:41:43.489194",
     "exception": false,
     "start_time": "2024-05-23T04:41:42.907863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results comparison (UFront vs Pytorch)\n",
      "\n",
      "Output index  0\n",
      "MAE:  1.1937577e-06\n",
      "RMSE: 1.4978546e-06\n",
      "COD: 1.0\n",
      "MPE: -1.254536e-05 %\n",
      "\n",
      "Output index  1\n",
      "MAE:  5.525795e-07\n",
      "RMSE: 7.10377e-07\n",
      "COD: 1.0\n",
      "MPE: -0.0002558513 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Results comparison (UFront vs Pytorch)\")\n",
    "\n",
    "i = 0\n",
    "for a, b in zip(ufront_ret, torch_ret):\n",
    "    print(\"\\nOutput index \", i)\n",
    "    a = a.to_host() # ufront model output\n",
    "    b = b.detach().numpy() # pytorch model output\n",
    "    dif = a - b\n",
    "    mae = np.mean(abs(dif))\n",
    "    print(\"MAE: \", mae)\n",
    "    print(\"RMSE:\", rmse(torch.Tensor(a), torch.Tensor(b)).numpy())\n",
    "    print(\"COD:\", r_square(torch.Tensor(a), torch.Tensor(b)).numpy())\n",
    "    print(\"MPE:\", mpe(torch.Tensor(a), torch.Tensor(b)).numpy(), \"%\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c13445",
   "metadata": {
    "papermill": {
     "duration": 0.559557,
     "end_time": "2024-05-23T04:41:44.702415",
     "exception": false,
     "start_time": "2024-05-23T04:41:44.142858",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### High-level IR of UFront-Compiled Bert Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "57113a6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T04:41:45.856555Z",
     "iopub.status.busy": "2024-05-23T04:41:45.855658Z",
     "iopub.status.idle": "2024-05-23T04:41:45.866604Z",
     "shell.execute_reply": "2024-05-23T04:41:45.865747Z"
    },
    "papermill": {
     "duration": 0.611037,
     "end_time": "2024-05-23T04:41:45.872738",
     "exception": false,
     "start_time": "2024-05-23T04:41:45.261701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "func.func @forward(%input1: tensor<2x3xi32>, %input2: tensor<2x3xi32>, %input3: tensor<2x3xi32>) -> (tensor<2x3x768xf32>, tensor<2x768xf32>)  { \n",
      "\t%1=\"ufront.reshape\"(%input3){shape=[2, 1, 3]}:(tensor<2x3xi32>) -> tensor<2x1x3xi32>\n",
      "\t%2=\"ufront.reshape\"(%1){shape=[2, 1, 1, 3]}:(tensor<2x1x3xi32>) -> tensor<2x1x1x3xi32>\n",
      "\t%3=\"ufront.cast\"(%2){dtype=\"Float\"}:(tensor<2x1x1x3xi32>) -> tensor<2x1x1x3xf32>\n",
      "\t%4=\"ufront.ssub\"(%3){scalar=1.0, scalar_position=\"LEFT\"}:(tensor<2x1x1x3xf32>) -> tensor<2x1x1x3xf32>\n",
      "\t%5=\"ufront.smultiply\"(%4){scalar=-10000.0}:(tensor<2x1x1x3xf32>) -> tensor<2x1x1x3xf32>\n",
      "\t%6=\"ufront.parameter\"(){dtype=\"Int64\", initializer=\"0x5c24c33a40a0\", requires_grad=false}:() -> tensor<3xi64>\n",
      "\t%7=\"ufront.reshape\"(%6){shape=[1, 3]}:(tensor<3xi64>) -> tensor<1x3xi64>\n",
      "\t%8=\"ufront.expand\"(%7){sizes=[2, 3]}:(tensor<1x3xi64>) -> tensor<2x3xi64>\n",
      "\t%9=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24dbb00e80\", requires_grad=true}:() -> tensor<16000x768xf32>\n",
      "\t%10=\"ufront.embedding\"(%input1, %9){embedding_dim=768, num_embeddings=16000}:(tensor<2x3xi32>, tensor<16000x768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%11=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c5e28810\", requires_grad=true}:() -> tensor<512x768xf32>\n",
      "\t%12=\"ufront.embedding\"(%8, %11){embedding_dim=768, num_embeddings=512}:(tensor<2x3xi64>, tensor<512x768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%13=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c3408280\", requires_grad=true}:() -> tensor<2x768xf32>\n",
      "\t%14=\"ufront.embedding\"(%input2, %13){embedding_dim=768, num_embeddings=2}:(tensor<2x3xi32>, tensor<2x768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%15=\"ufront.add\"(%10, %12):(tensor<2x3x768xf32>, tensor<2x3x768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%16=\"ufront.add\"(%15, %14):(tensor<2x3x768xf32>, tensor<2x3x768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%17=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c3d817c0\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%18=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c4311300\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%19=\"ufront.layer_norm\"(%16, %17, %18){elementwise_affine=true, eps=0.000000000001, normalized_shape=[768], operand_segment_sizes=array<i32:1, 1, 1>}:(tensor<2x3x768xf32>, tensor<768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%20=\"ufront.dropout\"(%19){rate=0.1, seed=0, training=false}:(tensor<2x3x768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%21=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24d2325480\", requires_grad=true}:() -> tensor<768x768xf32>\n",
      "\t%22=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c42c6e40\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%23=\"ufront.linear\"(%20, %21, %22){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%24=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c8020fd0\", requires_grad=true}:() -> tensor<768x768xf32>\n",
      "\t%25=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c667ce00\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%26=\"ufront.linear\"(%20, %24, %25){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%27=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c77ecd60\", requires_grad=true}:() -> tensor<768x768xf32>\n",
      "\t%28=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c8349300\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%29=\"ufront.linear\"(%20, %27, %28){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%30=\"ufront.reshape\"(%23){shape=[2, 3, 12, 64]}:(tensor<2x3x768xf32>) -> tensor<2x3x12x64xf32>\n",
      "\t%31=\"ufront.transpose\"(%30){perms=[0, 2, 1, 3]}:(tensor<2x3x12x64xf32>) -> tensor<2x12x3x64xf32>\n",
      "\t%32=\"ufront.reshape\"(%26){shape=[2, 3, 12, 64]}:(tensor<2x3x768xf32>) -> tensor<2x3x12x64xf32>\n",
      "\t%33=\"ufront.transpose\"(%32){perms=[0, 2, 1, 3]}:(tensor<2x3x12x64xf32>) -> tensor<2x12x3x64xf32>\n",
      "\t%34=\"ufront.reshape\"(%29){shape=[2, 3, 12, 64]}:(tensor<2x3x768xf32>) -> tensor<2x3x12x64xf32>\n",
      "\t%35=\"ufront.transpose\"(%34){perms=[0, 2, 1, 3]}:(tensor<2x3x12x64xf32>) -> tensor<2x12x3x64xf32>\n",
      "\t%36=\"ufront.transpose\"(%33){perms=[0, 1, 3, 2]}:(tensor<2x12x3x64xf32>) -> tensor<2x12x64x3xf32>\n",
      "\t%37=\"ufront.batch_matmul\"(%31, %36):(tensor<2x12x3x64xf32>, tensor<2x12x64x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%38=\"ufront.struediv\"(%37){scalar=8.0}:(tensor<2x12x3x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%39=\"ufront.add\"(%38, %5):(tensor<2x12x3x3xf32>, tensor<2x1x1x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%40=\"ufront.softmax\"(%39):(tensor<2x12x3x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%41=\"ufront.dropout\"(%40){rate=0.1, seed=0, training=false}:(tensor<2x12x3x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%42=\"ufront.batch_matmul\"(%41, %35):(tensor<2x12x3x3xf32>, tensor<2x12x3x64xf32>) -> tensor<2x12x3x64xf32>\n",
      "\t%43=\"ufront.transpose\"(%42){perms=[0, 2, 1, 3]}:(tensor<2x12x3x64xf32>) -> tensor<2x3x12x64xf32>\n",
      "\t%44=\"ufront.reshape\"(%43){shape=[2, 3, 768]}:(tensor<2x3x12x64xf32>) -> tensor<2x3x768xf32>\n",
      "\t%45=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24d42a48c0\", requires_grad=true}:() -> tensor<768x768xf32>\n",
      "\t%46=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c43c0ac0\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%47=\"ufront.linear\"(%44, %45, %46){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%48=\"ufront.dropout\"(%47){rate=0.1, seed=0, training=false}:(tensor<2x3x768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%49=\"ufront.add\"(%48, %20):(tensor<2x3x768xf32>, tensor<2x3x768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%50=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c43cf3c0\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%51=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c334d180\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%52=\"ufront.layer_norm\"(%49, %50, %51){elementwise_affine=true, eps=0.000000000001, normalized_shape=[768], operand_segment_sizes=array<i32:1, 1, 1>}:(tensor<2x3x768xf32>, tensor<768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%53=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24d1365380\", requires_grad=true}:() -> tensor<768x3072xf32>\n",
      "\t%54=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c4607980\", requires_grad=true}:() -> tensor<3072xf32>\n",
      "\t%55=\"ufront.linear\"(%52, %53, %54){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x3072xf32>, tensor<3072xf32>) -> tensor<2x3x3072xf32>\n",
      "\t%56=\"ufront.gelu\"(%55){approximate=true}:(tensor<2x3x3072xf32>) -> tensor<2x3x3072xf32>\n",
      "\t%57=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24d0a65300\", requires_grad=true}:() -> tensor<3072x768xf32>\n",
      "\t%58=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c33da580\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%59=\"ufront.linear\"(%56, %57, %58){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x3072xf32>, tensor<3072x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%60=\"ufront.dropout\"(%59){rate=0.1, seed=0, training=false}:(tensor<2x3x768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%61=\"ufront.add\"(%60, %52):(tensor<2x3x768xf32>, tensor<2x3x768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%62=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c47d14c0\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%63=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24d4172340\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%64=\"ufront.layer_norm\"(%61, %62, %63){elementwise_affine=true, eps=0.000000000001, normalized_shape=[768], operand_segment_sizes=array<i32:1, 1, 1>}:(tensor<2x3x768xf32>, tensor<768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%65=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24d79fe940\", requires_grad=true}:() -> tensor<768x768xf32>\n",
      "\t%66=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24d4bb86c0\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%67=\"ufront.linear\"(%64, %65, %66){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%68=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24d3c42f50\", requires_grad=true}:() -> tensor<768x768xf32>\n",
      "\t%69=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c43102c0\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%70=\"ufront.linear\"(%64, %68, %69){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%71=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24d6f03d90\", requires_grad=true}:() -> tensor<768x768xf32>\n",
      "\t%72=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c34b1a00\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%73=\"ufront.linear\"(%64, %71, %72){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%74=\"ufront.reshape\"(%67){shape=[2, 3, 12, 64]}:(tensor<2x3x768xf32>) -> tensor<2x3x12x64xf32>\n",
      "\t%75=\"ufront.transpose\"(%74){perms=[0, 2, 1, 3]}:(tensor<2x3x12x64xf32>) -> tensor<2x12x3x64xf32>\n",
      "\t%76=\"ufront.reshape\"(%70){shape=[2, 3, 12, 64]}:(tensor<2x3x768xf32>) -> tensor<2x3x12x64xf32>\n",
      "\t%77=\"ufront.transpose\"(%76){perms=[0, 2, 1, 3]}:(tensor<2x3x12x64xf32>) -> tensor<2x12x3x64xf32>\n",
      "\t%78=\"ufront.reshape\"(%73){shape=[2, 3, 12, 64]}:(tensor<2x3x768xf32>) -> tensor<2x3x12x64xf32>\n",
      "\t%79=\"ufront.transpose\"(%78){perms=[0, 2, 1, 3]}:(tensor<2x3x12x64xf32>) -> tensor<2x12x3x64xf32>\n",
      "\t%80=\"ufront.transpose\"(%77){perms=[0, 1, 3, 2]}:(tensor<2x12x3x64xf32>) -> tensor<2x12x64x3xf32>\n",
      "\t%81=\"ufront.batch_matmul\"(%75, %80):(tensor<2x12x3x64xf32>, tensor<2x12x64x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%82=\"ufront.struediv\"(%81){scalar=8.0}:(tensor<2x12x3x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%83=\"ufront.add\"(%82, %5):(tensor<2x12x3x3xf32>, tensor<2x1x1x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%84=\"ufront.softmax\"(%83):(tensor<2x12x3x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%85=\"ufront.dropout\"(%84){rate=0.1, seed=0, training=false}:(tensor<2x12x3x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%86=\"ufront.batch_matmul\"(%85, %79):(tensor<2x12x3x3xf32>, tensor<2x12x3x64xf32>) -> tensor<2x12x3x64xf32>\n",
      "\t%87=\"ufront.transpose\"(%86){perms=[0, 2, 1, 3]}:(tensor<2x12x3x64xf32>) -> tensor<2x3x12x64xf32>\n",
      "\t%88=\"ufront.reshape\"(%87){shape=[2, 3, 768]}:(tensor<2x3x12x64xf32>) -> tensor<2x3x768xf32>\n",
      "\t%89=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24d20e5420\", requires_grad=true}:() -> tensor<768x768xf32>\n",
      "\t%90=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c3f97500\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%91=\"ufront.linear\"(%88, %89, %90){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%92=\"ufront.dropout\"(%91){rate=0.1, seed=0, training=false}:(tensor<2x3x768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%93=\"ufront.add\"(%92, %64):(tensor<2x3x768xf32>, tensor<2x3x768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%94=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24cb7c9890\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%95=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c42d8890\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%96=\"ufront.layer_norm\"(%93, %94, %95){elementwise_affine=true, eps=0.000000000001, normalized_shape=[768], operand_segment_sizes=array<i32:1, 1, 1>}:(tensor<2x3x768xf32>, tensor<768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%97=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24cd035a10\", requires_grad=true}:() -> tensor<768x3072xf32>\n",
      "\t%98=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24d47744c0\", requires_grad=true}:() -> tensor<3072xf32>\n",
      "\t%99=\"ufront.linear\"(%96, %97, %98){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x3072xf32>, tensor<3072xf32>) -> tensor<2x3x3072xf32>\n",
      "\t%100=\"ufront.gelu\"(%99){approximate=true}:(tensor<2x3x3072xf32>) -> tensor<2x3x3072xf32>\n",
      "\t%101=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24e4ad6340\", requires_grad=true}:() -> tensor<3072x768xf32>\n",
      "\t%102=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c3652e10\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%103=\"ufront.linear\"(%100, %101, %102){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x3072xf32>, tensor<3072x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%104=\"ufront.dropout\"(%103){rate=0.1, seed=0, training=false}:(tensor<2x3x768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%105=\"ufront.add\"(%104, %96):(tensor<2x3x768xf32>, tensor<2x3x768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%106=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c353ba90\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%107=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c43e0a70\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%108=\"ufront.layer_norm\"(%105, %106, %107){elementwise_affine=true, eps=0.000000000001, normalized_shape=[768], operand_segment_sizes=array<i32:1, 1, 1>}:(tensor<2x3x768xf32>, tensor<768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%109=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24d1ea5410\", requires_grad=true}:() -> tensor<768x768xf32>\n",
      "\t%110=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c37b4300\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%111=\"ufront.linear\"(%108, %109, %110){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%112=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c7d48580\", requires_grad=true}:() -> tensor<768x768xf32>\n",
      "\t%113=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c3e24240\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%114=\"ufront.linear\"(%108, %112, %113){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%115=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24e5cd6360\", requires_grad=true}:() -> tensor<768x768xf32>\n",
      "\t%116=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c4394680\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%117=\"ufront.linear\"(%108, %115, %116){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%118=\"ufront.reshape\"(%111){shape=[2, 3, 12, 64]}:(tensor<2x3x768xf32>) -> tensor<2x3x12x64xf32>\n",
      "\t%119=\"ufront.transpose\"(%118){perms=[0, 2, 1, 3]}:(tensor<2x3x12x64xf32>) -> tensor<2x12x3x64xf32>\n",
      "\t%120=\"ufront.reshape\"(%114){shape=[2, 3, 12, 64]}:(tensor<2x3x768xf32>) -> tensor<2x3x12x64xf32>\n",
      "\t%121=\"ufront.transpose\"(%120){perms=[0, 2, 1, 3]}:(tensor<2x3x12x64xf32>) -> tensor<2x12x3x64xf32>\n",
      "\t%122=\"ufront.reshape\"(%117){shape=[2, 3, 12, 64]}:(tensor<2x3x768xf32>) -> tensor<2x3x12x64xf32>\n",
      "\t%123=\"ufront.transpose\"(%122){perms=[0, 2, 1, 3]}:(tensor<2x3x12x64xf32>) -> tensor<2x12x3x64xf32>\n",
      "\t%124=\"ufront.transpose\"(%121){perms=[0, 1, 3, 2]}:(tensor<2x12x3x64xf32>) -> tensor<2x12x64x3xf32>\n",
      "\t%125=\"ufront.batch_matmul\"(%119, %124):(tensor<2x12x3x64xf32>, tensor<2x12x64x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%126=\"ufront.struediv\"(%125){scalar=8.0}:(tensor<2x12x3x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%127=\"ufront.add\"(%126, %5):(tensor<2x12x3x3xf32>, tensor<2x1x1x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%128=\"ufront.softmax\"(%127):(tensor<2x12x3x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%129=\"ufront.dropout\"(%128){rate=0.1, seed=0, training=false}:(tensor<2x12x3x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%130=\"ufront.batch_matmul\"(%129, %123):(tensor<2x12x3x3xf32>, tensor<2x12x3x64xf32>) -> tensor<2x12x3x64xf32>\n",
      "\t%131=\"ufront.transpose\"(%130){perms=[0, 2, 1, 3]}:(tensor<2x12x3x64xf32>) -> tensor<2x3x12x64xf32>\n",
      "\t%132=\"ufront.reshape\"(%131){shape=[2, 3, 768]}:(tensor<2x3x12x64xf32>) -> tensor<2x3x768xf32>\n",
      "\t%133=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24d8afacf0\", requires_grad=true}:() -> tensor<768x768xf32>\n",
      "\t%134=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c43d23f0\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%135=\"ufront.linear\"(%132, %133, %134){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%136=\"ufront.dropout\"(%135){rate=0.1, seed=0, training=false}:(tensor<2x3x768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%137=\"ufront.add\"(%136, %108):(tensor<2x3x768xf32>, tensor<2x3x768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%138=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c34fd900\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%139=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c37b2c70\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%140=\"ufront.layer_norm\"(%137, %138, %139){elementwise_affine=true, eps=0.000000000001, normalized_shape=[768], operand_segment_sizes=array<i32:1, 1, 1>}:(tensor<2x3x768xf32>, tensor<768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%141=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24d98031a0\", requires_grad=true}:() -> tensor<768x3072xf32>\n",
      "\t%142=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c45fc6c0\", requires_grad=true}:() -> tensor<3072xf32>\n",
      "\t%143=\"ufront.linear\"(%140, %141, %142){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x3072xf32>, tensor<3072xf32>) -> tensor<2x3x3072xf32>\n",
      "\t%144=\"ufront.gelu\"(%143){approximate=true}:(tensor<2x3x3072xf32>) -> tensor<2x3x3072xf32>\n",
      "\t%145=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24daa031c0\", requires_grad=true}:() -> tensor<3072x768xf32>\n",
      "\t%146=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24d4bbaa20\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%147=\"ufront.linear\"(%144, %145, %146){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x3072xf32>, tensor<3072x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%148=\"ufront.dropout\"(%147){rate=0.1, seed=0, training=false}:(tensor<2x3x768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%149=\"ufront.add\"(%148, %140):(tensor<2x3x768xf32>, tensor<2x3x768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%150=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24d4bb9a10\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%151=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c44ba4c0\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%152=\"ufront.layer_norm\"(%149, %150, %151){elementwise_affine=true, eps=0.000000000001, normalized_shape=[768], operand_segment_sizes=array<i32:1, 1, 1>}:(tensor<2x3x768xf32>, tensor<768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%153=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24d8fc3d40\", requires_grad=true}:() -> tensor<768x768xf32>\n",
      "\t%154=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24cab47680\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%155=\"ufront.linear\"(%152, %153, %154){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%156=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24db7831f0\", requires_grad=true}:() -> tensor<768x768xf32>\n",
      "\t%157=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24cb7b5f90\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%158=\"ufront.linear\"(%152, %156, %157){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%159=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24e6156380\", requires_grad=true}:() -> tensor<768x768xf32>\n",
      "\t%160=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24d4af5c70\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%161=\"ufront.linear\"(%152, %159, %160){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%162=\"ufront.reshape\"(%155){shape=[2, 3, 12, 64]}:(tensor<2x3x768xf32>) -> tensor<2x3x12x64xf32>\n",
      "\t%163=\"ufront.transpose\"(%162){perms=[0, 2, 1, 3]}:(tensor<2x3x12x64xf32>) -> tensor<2x12x3x64xf32>\n",
      "\t%164=\"ufront.reshape\"(%158){shape=[2, 3, 12, 64]}:(tensor<2x3x768xf32>) -> tensor<2x3x12x64xf32>\n",
      "\t%165=\"ufront.transpose\"(%164){perms=[0, 2, 1, 3]}:(tensor<2x3x12x64xf32>) -> tensor<2x12x3x64xf32>\n",
      "\t%166=\"ufront.reshape\"(%161){shape=[2, 3, 12, 64]}:(tensor<2x3x768xf32>) -> tensor<2x3x12x64xf32>\n",
      "\t%167=\"ufront.transpose\"(%166){perms=[0, 2, 1, 3]}:(tensor<2x3x12x64xf32>) -> tensor<2x12x3x64xf32>\n",
      "\t%168=\"ufront.transpose\"(%165){perms=[0, 1, 3, 2]}:(tensor<2x12x3x64xf32>) -> tensor<2x12x64x3xf32>\n",
      "\t%169=\"ufront.batch_matmul\"(%163, %168):(tensor<2x12x3x64xf32>, tensor<2x12x64x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%170=\"ufront.struediv\"(%169){scalar=8.0}:(tensor<2x12x3x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%171=\"ufront.add\"(%170, %5):(tensor<2x12x3x3xf32>, tensor<2x1x1x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%172=\"ufront.softmax\"(%171):(tensor<2x12x3x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%173=\"ufront.dropout\"(%172){rate=0.1, seed=0, training=false}:(tensor<2x12x3x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%174=\"ufront.batch_matmul\"(%173, %167):(tensor<2x12x3x3xf32>, tensor<2x12x3x64xf32>) -> tensor<2x12x3x64xf32>\n",
      "\t%175=\"ufront.transpose\"(%174){perms=[0, 2, 1, 3]}:(tensor<2x12x3x64xf32>) -> tensor<2x3x12x64xf32>\n",
      "\t%176=\"ufront.reshape\"(%175){shape=[2, 3, 768]}:(tensor<2x3x12x64xf32>) -> tensor<2x3x768xf32>\n",
      "\t%177=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24ebfc18c0\", requires_grad=true}:() -> tensor<768x768xf32>\n",
      "\t%178=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c68839f0\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%179=\"ufront.linear\"(%176, %177, %178){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%180=\"ufront.dropout\"(%179){rate=0.1, seed=0, training=false}:(tensor<2x3x768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%181=\"ufront.add\"(%180, %152):(tensor<2x3x768xf32>, tensor<2x3x768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%182=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c4c43cf0\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%183=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c5826640\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%184=\"ufront.layer_norm\"(%181, %182, %183){elementwise_affine=true, eps=0.000000000001, normalized_shape=[768], operand_segment_sizes=array<i32:1, 1, 1>}:(tensor<2x3x768xf32>, tensor<768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%185=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24cdf2ce90\", requires_grad=true}:() -> tensor<768x3072xf32>\n",
      "\t%186=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c5fa8820\", requires_grad=true}:() -> tensor<3072xf32>\n",
      "\t%187=\"ufront.linear\"(%184, %185, %186){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x3072xf32>, tensor<3072xf32>) -> tensor<2x3x3072xf32>\n",
      "\t%188=\"ufront.gelu\"(%187){approximate=true}:(tensor<2x3x3072xf32>) -> tensor<2x3x3072xf32>\n",
      "\t%189=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24e3b16230\", requires_grad=true}:() -> tensor<3072x768xf32>\n",
      "\t%190=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c6621400\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%191=\"ufront.linear\"(%188, %189, %190){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x3072xf32>, tensor<3072x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%192=\"ufront.dropout\"(%191){rate=0.1, seed=0, training=false}:(tensor<2x3x768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%193=\"ufront.add\"(%192, %184):(tensor<2x3x768xf32>, tensor<2x3x768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%194=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24cb9f1150\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%195=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24cb9f1f10\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%196=\"ufront.layer_norm\"(%193, %194, %195){elementwise_affine=true, eps=0.000000000001, normalized_shape=[768], operand_segment_sizes=array<i32:1, 1, 1>}:(tensor<2x3x768xf32>, tensor<768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%197=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24ec4418e0\", requires_grad=true}:() -> tensor<768x768xf32>\n",
      "\t%198=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c42fd200\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%199=\"ufront.linear\"(%196, %197, %198){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%200=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24db5431e0\", requires_grad=true}:() -> tensor<768x768xf32>\n",
      "\t%201=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c33b96f0\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%202=\"ufront.linear\"(%196, %200, %201){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%203=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24e4416240\", requires_grad=true}:() -> tensor<768x768xf32>\n",
      "\t%204=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c42ffee0\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%205=\"ufront.linear\"(%196, %203, %204){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%206=\"ufront.reshape\"(%199){shape=[2, 3, 12, 64]}:(tensor<2x3x768xf32>) -> tensor<2x3x12x64xf32>\n",
      "\t%207=\"ufront.transpose\"(%206){perms=[0, 2, 1, 3]}:(tensor<2x3x12x64xf32>) -> tensor<2x12x3x64xf32>\n",
      "\t%208=\"ufront.reshape\"(%202){shape=[2, 3, 12, 64]}:(tensor<2x3x768xf32>) -> tensor<2x3x12x64xf32>\n",
      "\t%209=\"ufront.transpose\"(%208){perms=[0, 2, 1, 3]}:(tensor<2x3x12x64xf32>) -> tensor<2x12x3x64xf32>\n",
      "\t%210=\"ufront.reshape\"(%205){shape=[2, 3, 12, 64]}:(tensor<2x3x768xf32>) -> tensor<2x3x12x64xf32>\n",
      "\t%211=\"ufront.transpose\"(%210){perms=[0, 2, 1, 3]}:(tensor<2x3x12x64xf32>) -> tensor<2x12x3x64xf32>\n",
      "\t%212=\"ufront.transpose\"(%209){perms=[0, 1, 3, 2]}:(tensor<2x12x3x64xf32>) -> tensor<2x12x64x3xf32>\n",
      "\t%213=\"ufront.batch_matmul\"(%207, %212):(tensor<2x12x3x64xf32>, tensor<2x12x64x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%214=\"ufront.struediv\"(%213){scalar=8.0}:(tensor<2x12x3x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%215=\"ufront.add\"(%214, %5):(tensor<2x12x3x3xf32>, tensor<2x1x1x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%216=\"ufront.softmax\"(%215):(tensor<2x12x3x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%217=\"ufront.dropout\"(%216){rate=0.1, seed=0, training=false}:(tensor<2x12x3x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%218=\"ufront.batch_matmul\"(%217, %211):(tensor<2x12x3x3xf32>, tensor<2x12x3x64xf32>) -> tensor<2x12x3x64xf32>\n",
      "\t%219=\"ufront.transpose\"(%218){perms=[0, 2, 1, 3]}:(tensor<2x12x3x64xf32>) -> tensor<2x3x12x64xf32>\n",
      "\t%220=\"ufront.reshape\"(%219){shape=[2, 3, 768]}:(tensor<2x3x12x64xf32>) -> tensor<2x3x768xf32>\n",
      "\t%221=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24e4896260\", requires_grad=true}:() -> tensor<768x768xf32>\n",
      "\t%222=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24cb836bf0\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%223=\"ufront.linear\"(%220, %221, %222){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%224=\"ufront.dropout\"(%223){rate=0.1, seed=0, training=false}:(tensor<2x3x768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%225=\"ufront.add\"(%224, %196):(tensor<2x3x768xf32>, tensor<2x3x768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%226=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c67ad4c0\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%227=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c67af0e0\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%228=\"ufront.layer_norm\"(%225, %226, %227){elementwise_affine=true, eps=0.000000000001, normalized_shape=[768], operand_segment_sizes=array<i32:1, 1, 1>}:(tensor<2x3x768xf32>, tensor<768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%229=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24df2e0ea0\", requires_grad=true}:() -> tensor<768x3072xf32>\n",
      "\t%230=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c580c6b0\", requires_grad=true}:() -> tensor<3072xf32>\n",
      "\t%231=\"ufront.linear\"(%228, %229, %230){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x3072xf32>, tensor<3072xf32>) -> tensor<2x3x3072xf32>\n",
      "\t%232=\"ufront.gelu\"(%231){approximate=true}:(tensor<2x3x3072xf32>) -> tensor<2x3x3072xf32>\n",
      "\t%233=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24e16e0ee0\", requires_grad=true}:() -> tensor<3072x768xf32>\n",
      "\t%234=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24cb864840\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%235=\"ufront.linear\"(%232, %233, %234){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x3072xf32>, tensor<3072x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%236=\"ufront.dropout\"(%235){rate=0.1, seed=0, training=false}:(tensor<2x3x768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%237=\"ufront.add\"(%236, %228):(tensor<2x3x768xf32>, tensor<2x3x768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%238=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c67a1ce0\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%239=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24d3136c90\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%240=\"ufront.layer_norm\"(%237, %238, %239){elementwise_affine=true, eps=0.000000000001, normalized_shape=[768], operand_segment_sizes=array<i32:1, 1, 1>}:(tensor<2x3x768xf32>, tensor<768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%241=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24cea6ceb0\", requires_grad=true}:() -> tensor<768x768xf32>\n",
      "\t%242=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c67a2cf0\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%243=\"ufront.linear\"(%240, %241, %242){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%244=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24e2b56220\", requires_grad=true}:() -> tensor<768x768xf32>\n",
      "\t%245=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c4c51520\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%246=\"ufront.linear\"(%240, %244, %245){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%247=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24d07acef0\", requires_grad=true}:() -> tensor<768x768xf32>\n",
      "\t%248=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c4319c90\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%249=\"ufront.linear\"(%240, %247, %248){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%250=\"ufront.reshape\"(%243){shape=[2, 3, 12, 64]}:(tensor<2x3x768xf32>) -> tensor<2x3x12x64xf32>\n",
      "\t%251=\"ufront.transpose\"(%250){perms=[0, 2, 1, 3]}:(tensor<2x3x12x64xf32>) -> tensor<2x12x3x64xf32>\n",
      "\t%252=\"ufront.reshape\"(%246){shape=[2, 3, 12, 64]}:(tensor<2x3x768xf32>) -> tensor<2x3x12x64xf32>\n",
      "\t%253=\"ufront.transpose\"(%252){perms=[0, 2, 1, 3]}:(tensor<2x3x12x64xf32>) -> tensor<2x12x3x64xf32>\n",
      "\t%254=\"ufront.reshape\"(%249){shape=[2, 3, 12, 64]}:(tensor<2x3x768xf32>) -> tensor<2x3x12x64xf32>\n",
      "\t%255=\"ufront.transpose\"(%254){perms=[0, 2, 1, 3]}:(tensor<2x3x12x64xf32>) -> tensor<2x12x3x64xf32>\n",
      "\t%256=\"ufront.transpose\"(%253){perms=[0, 1, 3, 2]}:(tensor<2x12x3x64xf32>) -> tensor<2x12x64x3xf32>\n",
      "\t%257=\"ufront.batch_matmul\"(%251, %256):(tensor<2x12x3x64xf32>, tensor<2x12x64x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%258=\"ufront.struediv\"(%257){scalar=8.0}:(tensor<2x12x3x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%259=\"ufront.add\"(%258, %5):(tensor<2x12x3x3xf32>, tensor<2x1x1x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%260=\"ufront.softmax\"(%259):(tensor<2x12x3x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%261=\"ufront.dropout\"(%260){rate=0.1, seed=0, training=false}:(tensor<2x12x3x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%262=\"ufront.batch_matmul\"(%261, %255):(tensor<2x12x3x3xf32>, tensor<2x12x3x64xf32>) -> tensor<2x12x3x64xf32>\n",
      "\t%263=\"ufront.transpose\"(%262){perms=[0, 2, 1, 3]}:(tensor<2x12x3x64xf32>) -> tensor<2x3x12x64xf32>\n",
      "\t%264=\"ufront.reshape\"(%263){shape=[2, 3, 768]}:(tensor<2x3x12x64xf32>) -> tensor<2x3x768xf32>\n",
      "\t%265=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24dfe20ec0\", requires_grad=true}:() -> tensor<768x768xf32>\n",
      "\t%266=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c33fb4e0\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%267=\"ufront.linear\"(%264, %265, %266){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%268=\"ufront.dropout\"(%267){rate=0.1, seed=0, training=false}:(tensor<2x3x768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%269=\"ufront.add\"(%268, %240):(tensor<2x3x768xf32>, tensor<2x3x768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%270=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c33c21c0\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%271=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c338c610\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%272=\"ufront.layer_norm\"(%269, %270, %271){elementwise_affine=true, eps=0.000000000001, normalized_shape=[768], operand_segment_sizes=array<i32:1, 1, 1>}:(tensor<2x3x768xf32>, tensor<768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%273=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24fb9f2f40\", requires_grad=true}:() -> tensor<768x3072xf32>\n",
      "\t%274=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c33cd650\", requires_grad=true}:() -> tensor<3072xf32>\n",
      "\t%275=\"ufront.linear\"(%272, %273, %274){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x3072xf32>, tensor<3072xf32>) -> tensor<2x3x3072xf32>\n",
      "\t%276=\"ufront.gelu\"(%275){approximate=true}:(tensor<2x3x3072xf32>) -> tensor<2x3x3072xf32>\n",
      "\t%277=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24fc2f2f50\", requires_grad=true}:() -> tensor<3072x768xf32>\n",
      "\t%278=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c338fa50\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%279=\"ufront.linear\"(%276, %277, %278){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x3072xf32>, tensor<3072x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%280=\"ufront.dropout\"(%279){rate=0.1, seed=0, training=false}:(tensor<2x3x768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%281=\"ufront.add\"(%280, %272):(tensor<2x3x768xf32>, tensor<2x3x768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%282=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c37a9f80\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%283=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24cb7d55b0\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%284=\"ufront.layer_norm\"(%281, %282, %283){elementwise_affine=true, eps=0.000000000001, normalized_shape=[768], operand_segment_sizes=array<i32:1, 1, 1>}:(tensor<2x3x768xf32>, tensor<768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%285=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24e0de0ed0\", requires_grad=true}:() -> tensor<768x768xf32>\n",
      "\t%286=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24cb7d89f0\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%287=\"ufront.linear\"(%284, %285, %286){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%288=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24e1260ef0\", requires_grad=true}:() -> tensor<768x768xf32>\n",
      "\t%289=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24cdf25dc0\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%290=\"ufront.linear\"(%284, %288, %289){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%291=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24d032ced0\", requires_grad=true}:() -> tensor<768x768xf32>\n",
      "\t%292=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24cdf291d0\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%293=\"ufront.linear\"(%284, %291, %292){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%294=\"ufront.reshape\"(%287){shape=[2, 3, 12, 64]}:(tensor<2x3x768xf32>) -> tensor<2x3x12x64xf32>\n",
      "\t%295=\"ufront.transpose\"(%294){perms=[0, 2, 1, 3]}:(tensor<2x3x12x64xf32>) -> tensor<2x12x3x64xf32>\n",
      "\t%296=\"ufront.reshape\"(%290){shape=[2, 3, 12, 64]}:(tensor<2x3x768xf32>) -> tensor<2x3x12x64xf32>\n",
      "\t%297=\"ufront.transpose\"(%296){perms=[0, 2, 1, 3]}:(tensor<2x3x12x64xf32>) -> tensor<2x12x3x64xf32>\n",
      "\t%298=\"ufront.reshape\"(%293){shape=[2, 3, 12, 64]}:(tensor<2x3x768xf32>) -> tensor<2x3x12x64xf32>\n",
      "\t%299=\"ufront.transpose\"(%298){perms=[0, 2, 1, 3]}:(tensor<2x3x12x64xf32>) -> tensor<2x12x3x64xf32>\n",
      "\t%300=\"ufront.transpose\"(%297){perms=[0, 1, 3, 2]}:(tensor<2x12x3x64xf32>) -> tensor<2x12x64x3xf32>\n",
      "\t%301=\"ufront.batch_matmul\"(%295, %300):(tensor<2x12x3x64xf32>, tensor<2x12x64x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%302=\"ufront.struediv\"(%301){scalar=8.0}:(tensor<2x12x3x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%303=\"ufront.add\"(%302, %5):(tensor<2x12x3x3xf32>, tensor<2x1x1x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%304=\"ufront.softmax\"(%303):(tensor<2x12x3x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%305=\"ufront.dropout\"(%304){rate=0.1, seed=0, training=false}:(tensor<2x12x3x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%306=\"ufront.batch_matmul\"(%305, %299):(tensor<2x12x3x3xf32>, tensor<2x12x3x64xf32>) -> tensor<2x12x3x64xf32>\n",
      "\t%307=\"ufront.transpose\"(%306){perms=[0, 2, 1, 3]}:(tensor<2x12x3x64xf32>) -> tensor<2x3x12x64xf32>\n",
      "\t%308=\"ufront.reshape\"(%307){shape=[2, 3, 768]}:(tensor<2x3x12x64xf32>) -> tensor<2x3x768xf32>\n",
      "\t%309=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24fd4f2f70\", requires_grad=true}:() -> tensor<768x768xf32>\n",
      "\t%310=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c4c3e820\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%311=\"ufront.linear\"(%308, %309, %310){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%312=\"ufront.dropout\"(%311){rate=0.1, seed=0, training=false}:(tensor<2x3x768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%313=\"ufront.add\"(%312, %284):(tensor<2x3x768xf32>, tensor<2x3x768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%314=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24d46fe560\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%315=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24d4702850\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%316=\"ufront.layer_norm\"(%313, %314, %315){elementwise_affine=true, eps=0.000000000001, normalized_shape=[768], operand_segment_sizes=array<i32:1, 1, 1>}:(tensor<2x3x768xf32>, tensor<768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%317=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24ff232fb0\", requires_grad=true}:() -> tensor<768x3072xf32>\n",
      "\t%318=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c481d5c0\", requires_grad=true}:() -> tensor<3072xf32>\n",
      "\t%319=\"ufront.linear\"(%316, %317, %318){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x3072xf32>, tensor<3072xf32>) -> tensor<2x3x3072xf32>\n",
      "\t%320=\"ufront.gelu\"(%319){approximate=true}:(tensor<2x3x3072xf32>) -> tensor<2x3x3072xf32>\n",
      "\t%321=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24ffb32fc0\", requires_grad=true}:() -> tensor<3072x768xf32>\n",
      "\t%322=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24cb7ab220\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%323=\"ufront.linear\"(%320, %321, %322){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x3072xf32>, tensor<3072x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%324=\"ufront.dropout\"(%323){rate=0.1, seed=0, training=false}:(tensor<2x3x768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%325=\"ufront.add\"(%324, %316):(tensor<2x3x768xf32>, tensor<2x3x768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%326=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24cb4db6a0\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%327=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24cb4dc630\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%328=\"ufront.layer_norm\"(%325, %326, %327){elementwise_affine=true, eps=0.000000000001, normalized_shape=[768], operand_segment_sizes=array<i32:1, 1, 1>}:(tensor<2x3x768xf32>, tensor<768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%329=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24fd972f90\", requires_grad=true}:() -> tensor<768x768xf32>\n",
      "\t%330=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c46fd7f0\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%331=\"ufront.linear\"(%328, %329, %330){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%332=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24fb332f40\", requires_grad=true}:() -> tensor<768x768xf32>\n",
      "\t%333=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c46ff410\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%334=\"ufront.linear\"(%328, %332, %333){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%335=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24fedb2fc0\", requires_grad=true}:() -> tensor<768x768xf32>\n",
      "\t%336=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c57ff640\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%337=\"ufront.linear\"(%328, %335, %336){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%338=\"ufront.reshape\"(%331){shape=[2, 3, 12, 64]}:(tensor<2x3x768xf32>) -> tensor<2x3x12x64xf32>\n",
      "\t%339=\"ufront.transpose\"(%338){perms=[0, 2, 1, 3]}:(tensor<2x3x12x64xf32>) -> tensor<2x12x3x64xf32>\n",
      "\t%340=\"ufront.reshape\"(%334){shape=[2, 3, 12, 64]}:(tensor<2x3x768xf32>) -> tensor<2x3x12x64xf32>\n",
      "\t%341=\"ufront.transpose\"(%340){perms=[0, 2, 1, 3]}:(tensor<2x3x12x64xf32>) -> tensor<2x12x3x64xf32>\n",
      "\t%342=\"ufront.reshape\"(%337){shape=[2, 3, 12, 64]}:(tensor<2x3x768xf32>) -> tensor<2x3x12x64xf32>\n",
      "\t%343=\"ufront.transpose\"(%342){perms=[0, 2, 1, 3]}:(tensor<2x3x12x64xf32>) -> tensor<2x12x3x64xf32>\n",
      "\t%344=\"ufront.transpose\"(%341){perms=[0, 1, 3, 2]}:(tensor<2x12x3x64xf32>) -> tensor<2x12x64x3xf32>\n",
      "\t%345=\"ufront.batch_matmul\"(%339, %344):(tensor<2x12x3x64xf32>, tensor<2x12x64x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%346=\"ufront.struediv\"(%345){scalar=8.0}:(tensor<2x12x3x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%347=\"ufront.add\"(%346, %5):(tensor<2x12x3x3xf32>, tensor<2x1x1x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%348=\"ufront.softmax\"(%347):(tensor<2x12x3x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%349=\"ufront.dropout\"(%348){rate=0.1, seed=0, training=false}:(tensor<2x12x3x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%350=\"ufront.batch_matmul\"(%349, %343):(tensor<2x12x3x3xf32>, tensor<2x12x3x64xf32>) -> tensor<2x12x3x64xf32>\n",
      "\t%351=\"ufront.transpose\"(%350){perms=[0, 2, 1, 3]}:(tensor<2x12x3x64xf32>) -> tensor<2x3x12x64xf32>\n",
      "\t%352=\"ufront.reshape\"(%351){shape=[2, 3, 768]}:(tensor<2x3x12x64xf32>) -> tensor<2x3x768xf32>\n",
      "\t%353=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c2500f72ff0\", requires_grad=true}:() -> tensor<768x768xf32>\n",
      "\t%354=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c3457310\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%355=\"ufront.linear\"(%352, %353, %354){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%356=\"ufront.dropout\"(%355){rate=0.1, seed=0, training=false}:(tensor<2x3x768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%357=\"ufront.add\"(%356, %328):(tensor<2x3x768xf32>, tensor<2x3x768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%358=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c5518bf0\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%359=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c5519800\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%360=\"ufront.layer_norm\"(%357, %358, %359){elementwise_affine=true, eps=0.000000000001, normalized_shape=[768], operand_segment_sizes=array<i32:1, 1, 1>}:(tensor<2x3x768xf32>, tensor<768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%361=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c2502cb3030\", requires_grad=true}:() -> tensor<768x3072xf32>\n",
      "\t%362=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24dba5eff0\", requires_grad=true}:() -> tensor<3072xf32>\n",
      "\t%363=\"ufront.linear\"(%360, %361, %362){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x3072xf32>, tensor<3072xf32>) -> tensor<2x3x3072xf32>\n",
      "\t%364=\"ufront.gelu\"(%363){approximate=true}:(tensor<2x3x3072xf32>) -> tensor<2x3x3072xf32>\n",
      "\t%365=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c25035b3040\", requires_grad=true}:() -> tensor<3072x768xf32>\n",
      "\t%366=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c6894430\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%367=\"ufront.linear\"(%364, %365, %366){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x3072xf32>, tensor<3072x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%368=\"ufront.dropout\"(%367){rate=0.1, seed=0, training=false}:(tensor<2x3x768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%369=\"ufront.add\"(%368, %360):(tensor<2x3x768xf32>, tensor<2x3x768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%370=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24dba63180\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%371=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24d4d76170\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%372=\"ufront.layer_norm\"(%369, %370, %371){elementwise_affine=true, eps=0.000000000001, normalized_shape=[768], operand_segment_sizes=array<i32:1, 1, 1>}:(tensor<2x3x768xf32>, tensor<768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%373=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c2501f33000\", requires_grad=true}:() -> tensor<768x768xf32>\n",
      "\t%374=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24d4d75160\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%375=\"ufront.linear\"(%372, %373, %374){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%376=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24fe932fa0\", requires_grad=true}:() -> tensor<768x768xf32>\n",
      "\t%377=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c3400e20\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%378=\"ufront.linear\"(%372, %376, %377){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%379=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c2502833040\", requires_grad=true}:() -> tensor<768x768xf32>\n",
      "\t%380=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c3404840\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%381=\"ufront.linear\"(%372, %379, %380){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%382=\"ufront.reshape\"(%375){shape=[2, 3, 12, 64]}:(tensor<2x3x768xf32>) -> tensor<2x3x12x64xf32>\n",
      "\t%383=\"ufront.transpose\"(%382){perms=[0, 2, 1, 3]}:(tensor<2x3x12x64xf32>) -> tensor<2x12x3x64xf32>\n",
      "\t%384=\"ufront.reshape\"(%378){shape=[2, 3, 12, 64]}:(tensor<2x3x768xf32>) -> tensor<2x3x12x64xf32>\n",
      "\t%385=\"ufront.transpose\"(%384){perms=[0, 2, 1, 3]}:(tensor<2x3x12x64xf32>) -> tensor<2x12x3x64xf32>\n",
      "\t%386=\"ufront.reshape\"(%381){shape=[2, 3, 12, 64]}:(tensor<2x3x768xf32>) -> tensor<2x3x12x64xf32>\n",
      "\t%387=\"ufront.transpose\"(%386){perms=[0, 2, 1, 3]}:(tensor<2x3x12x64xf32>) -> tensor<2x12x3x64xf32>\n",
      "\t%388=\"ufront.transpose\"(%385){perms=[0, 1, 3, 2]}:(tensor<2x12x3x64xf32>) -> tensor<2x12x64x3xf32>\n",
      "\t%389=\"ufront.batch_matmul\"(%383, %388):(tensor<2x12x3x64xf32>, tensor<2x12x64x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%390=\"ufront.struediv\"(%389){scalar=8.0}:(tensor<2x12x3x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%391=\"ufront.add\"(%390, %5):(tensor<2x12x3x3xf32>, tensor<2x1x1x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%392=\"ufront.softmax\"(%391):(tensor<2x12x3x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%393=\"ufront.dropout\"(%392){rate=0.1, seed=0, training=false}:(tensor<2x12x3x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%394=\"ufront.batch_matmul\"(%393, %387):(tensor<2x12x3x3xf32>, tensor<2x12x3x64xf32>) -> tensor<2x12x3x64xf32>\n",
      "\t%395=\"ufront.transpose\"(%394){perms=[0, 2, 1, 3]}:(tensor<2x12x3x64xf32>) -> tensor<2x3x12x64xf32>\n",
      "\t%396=\"ufront.reshape\"(%395){shape=[2, 3, 768]}:(tensor<2x3x12x64xf32>) -> tensor<2x3x768xf32>\n",
      "\t%397=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c25049f3070\", requires_grad=true}:() -> tensor<768x768xf32>\n",
      "\t%398=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c65dd6c0\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%399=\"ufront.linear\"(%396, %397, %398){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%400=\"ufront.dropout\"(%399){rate=0.1, seed=0, training=false}:(tensor<2x3x768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%401=\"ufront.add\"(%400, %372):(tensor<2x3x768xf32>, tensor<2x3x768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%402=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c35dfa80\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%403=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c35dc3b0\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%404=\"ufront.layer_norm\"(%401, %402, %403){elementwise_affine=true, eps=0.000000000001, normalized_shape=[768], operand_segment_sizes=array<i32:1, 1, 1>}:(tensor<2x3x768xf32>, tensor<768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%405=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c25067330b0\", requires_grad=true}:() -> tensor<768x3072xf32>\n",
      "\t%406=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c68648c0\", requires_grad=true}:() -> tensor<3072xf32>\n",
      "\t%407=\"ufront.linear\"(%404, %405, %406){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x3072xf32>, tensor<3072xf32>) -> tensor<2x3x3072xf32>\n",
      "\t%408=\"ufront.gelu\"(%407){approximate=true}:(tensor<2x3x3072xf32>) -> tensor<2x3x3072xf32>\n",
      "\t%409=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c25070330c0\", requires_grad=true}:() -> tensor<3072x768xf32>\n",
      "\t%410=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24d4c90f70\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%411=\"ufront.linear\"(%408, %409, %410){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x3072xf32>, tensor<3072x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%412=\"ufront.dropout\"(%411){rate=0.1, seed=0, training=false}:(tensor<2x3x768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%413=\"ufront.add\"(%412, %404):(tensor<2x3x768xf32>, tensor<2x3x768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%414=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24cb8fa220\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%415=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24cb8fb060\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%416=\"ufront.layer_norm\"(%413, %414, %415){elementwise_affine=true, eps=0.000000000001, normalized_shape=[768], operand_segment_sizes=array<i32:1, 1, 1>}:(tensor<2x3x768xf32>, tensor<768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%417=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c25059b3080\", requires_grad=true}:() -> tensor<768x768xf32>\n",
      "\t%418=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c68680a0\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%419=\"ufront.linear\"(%416, %417, %418){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%420=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c25023b3020\", requires_grad=true}:() -> tensor<768x768xf32>\n",
      "\t%421=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c46142e0\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%422=\"ufront.linear\"(%416, %420, %421){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%423=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c25062b30c0\", requires_grad=true}:() -> tensor<768x768xf32>\n",
      "\t%424=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c487c450\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%425=\"ufront.linear\"(%416, %423, %424){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%426=\"ufront.reshape\"(%419){shape=[2, 3, 12, 64]}:(tensor<2x3x768xf32>) -> tensor<2x3x12x64xf32>\n",
      "\t%427=\"ufront.transpose\"(%426){perms=[0, 2, 1, 3]}:(tensor<2x3x12x64xf32>) -> tensor<2x12x3x64xf32>\n",
      "\t%428=\"ufront.reshape\"(%422){shape=[2, 3, 12, 64]}:(tensor<2x3x768xf32>) -> tensor<2x3x12x64xf32>\n",
      "\t%429=\"ufront.transpose\"(%428){perms=[0, 2, 1, 3]}:(tensor<2x3x12x64xf32>) -> tensor<2x12x3x64xf32>\n",
      "\t%430=\"ufront.reshape\"(%425){shape=[2, 3, 12, 64]}:(tensor<2x3x768xf32>) -> tensor<2x3x12x64xf32>\n",
      "\t%431=\"ufront.transpose\"(%430){perms=[0, 2, 1, 3]}:(tensor<2x3x12x64xf32>) -> tensor<2x12x3x64xf32>\n",
      "\t%432=\"ufront.transpose\"(%429){perms=[0, 1, 3, 2]}:(tensor<2x12x3x64xf32>) -> tensor<2x12x64x3xf32>\n",
      "\t%433=\"ufront.batch_matmul\"(%427, %432):(tensor<2x12x3x64xf32>, tensor<2x12x64x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%434=\"ufront.struediv\"(%433){scalar=8.0}:(tensor<2x12x3x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%435=\"ufront.add\"(%434, %5):(tensor<2x12x3x3xf32>, tensor<2x1x1x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%436=\"ufront.softmax\"(%435):(tensor<2x12x3x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%437=\"ufront.dropout\"(%436){rate=0.1, seed=0, training=false}:(tensor<2x12x3x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%438=\"ufront.batch_matmul\"(%437, %431):(tensor<2x12x3x3xf32>, tensor<2x12x3x64xf32>) -> tensor<2x12x3x64xf32>\n",
      "\t%439=\"ufront.transpose\"(%438){perms=[0, 2, 1, 3]}:(tensor<2x12x3x64xf32>) -> tensor<2x3x12x64xf32>\n",
      "\t%440=\"ufront.reshape\"(%439){shape=[2, 3, 768]}:(tensor<2x3x12x64xf32>) -> tensor<2x3x768xf32>\n",
      "\t%441=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c25084730f0\", requires_grad=true}:() -> tensor<768x768xf32>\n",
      "\t%442=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24cab57a60\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%443=\"ufront.linear\"(%440, %441, %442){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%444=\"ufront.dropout\"(%443){rate=0.1, seed=0, training=false}:(tensor<2x3x768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%445=\"ufront.add\"(%444, %416):(tensor<2x3x768xf32>, tensor<2x3x768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%446=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c46238c0\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%447=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c4624890\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%448=\"ufront.layer_norm\"(%445, %446, %447){elementwise_affine=true, eps=0.000000000001, normalized_shape=[768], operand_segment_sizes=array<i32:1, 1, 1>}:(tensor<2x3x768xf32>, tensor<768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%449=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c250a1b3130\", requires_grad=true}:() -> tensor<768x3072xf32>\n",
      "\t%450=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c4da0760\", requires_grad=true}:() -> tensor<3072xf32>\n",
      "\t%451=\"ufront.linear\"(%448, %449, %450){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x3072xf32>, tensor<3072xf32>) -> tensor<2x3x3072xf32>\n",
      "\t%452=\"ufront.gelu\"(%451){approximate=true}:(tensor<2x3x3072xf32>) -> tensor<2x3x3072xf32>\n",
      "\t%453=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c250aab3140\", requires_grad=true}:() -> tensor<3072x768xf32>\n",
      "\t%454=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c4d9d750\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%455=\"ufront.linear\"(%452, %453, %454){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x3072xf32>, tensor<3072x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%456=\"ufront.dropout\"(%455){rate=0.1, seed=0, training=false}:(tensor<2x3x768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%457=\"ufront.add\"(%456, %448):(tensor<2x3x768xf32>, tensor<2x3x768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%458=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c3d540f0\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%459=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c3d55c80\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%460=\"ufront.layer_norm\"(%457, %458, %459){elementwise_affine=true, eps=0.000000000001, normalized_shape=[768], operand_segment_sizes=array<i32:1, 1, 1>}:(tensor<2x3x768xf32>, tensor<768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%461=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c2509433100\", requires_grad=true}:() -> tensor<768x768xf32>\n",
      "\t%462=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c3e1f860\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%463=\"ufront.linear\"(%460, %461, %462){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%464=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c2505e330a0\", requires_grad=true}:() -> tensor<768x768xf32>\n",
      "\t%465=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c3e1d840\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%466=\"ufront.linear\"(%460, %464, %465){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%467=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c2509d33140\", requires_grad=true}:() -> tensor<768x768xf32>\n",
      "\t%468=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c42e3db0\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%469=\"ufront.linear\"(%460, %467, %468){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%470=\"ufront.reshape\"(%463){shape=[2, 3, 12, 64]}:(tensor<2x3x768xf32>) -> tensor<2x3x12x64xf32>\n",
      "\t%471=\"ufront.transpose\"(%470){perms=[0, 2, 1, 3]}:(tensor<2x3x12x64xf32>) -> tensor<2x12x3x64xf32>\n",
      "\t%472=\"ufront.reshape\"(%466){shape=[2, 3, 12, 64]}:(tensor<2x3x768xf32>) -> tensor<2x3x12x64xf32>\n",
      "\t%473=\"ufront.transpose\"(%472){perms=[0, 2, 1, 3]}:(tensor<2x3x12x64xf32>) -> tensor<2x12x3x64xf32>\n",
      "\t%474=\"ufront.reshape\"(%469){shape=[2, 3, 12, 64]}:(tensor<2x3x768xf32>) -> tensor<2x3x12x64xf32>\n",
      "\t%475=\"ufront.transpose\"(%474){perms=[0, 2, 1, 3]}:(tensor<2x3x12x64xf32>) -> tensor<2x12x3x64xf32>\n",
      "\t%476=\"ufront.transpose\"(%473){perms=[0, 1, 3, 2]}:(tensor<2x12x3x64xf32>) -> tensor<2x12x64x3xf32>\n",
      "\t%477=\"ufront.batch_matmul\"(%471, %476):(tensor<2x12x3x64xf32>, tensor<2x12x64x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%478=\"ufront.struediv\"(%477){scalar=8.0}:(tensor<2x12x3x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%479=\"ufront.add\"(%478, %5):(tensor<2x12x3x3xf32>, tensor<2x1x1x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%480=\"ufront.softmax\"(%479):(tensor<2x12x3x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%481=\"ufront.dropout\"(%480){rate=0.1, seed=0, training=false}:(tensor<2x12x3x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%482=\"ufront.batch_matmul\"(%481, %475):(tensor<2x12x3x3xf32>, tensor<2x12x3x64xf32>) -> tensor<2x12x3x64xf32>\n",
      "\t%483=\"ufront.transpose\"(%482){perms=[0, 2, 1, 3]}:(tensor<2x12x3x64xf32>) -> tensor<2x3x12x64xf32>\n",
      "\t%484=\"ufront.reshape\"(%483){shape=[2, 3, 768]}:(tensor<2x3x12x64xf32>) -> tensor<2x3x768xf32>\n",
      "\t%485=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c250bef3170\", requires_grad=true}:() -> tensor<768x768xf32>\n",
      "\t%486=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c460d990\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%487=\"ufront.linear\"(%484, %485, %486){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%488=\"ufront.dropout\"(%487){rate=0.1, seed=0, training=false}:(tensor<2x3x768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%489=\"ufront.add\"(%488, %460):(tensor<2x3x768xf32>, tensor<2x3x768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%490=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c46130b0\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%491=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c46120a0\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%492=\"ufront.layer_norm\"(%489, %490, %491){elementwise_affine=true, eps=0.000000000001, normalized_shape=[768], operand_segment_sizes=array<i32:1, 1, 1>}:(tensor<2x3x768xf32>, tensor<768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%493=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c250dc331b0\", requires_grad=true}:() -> tensor<768x3072xf32>\n",
      "\t%494=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24cb95f070\", requires_grad=true}:() -> tensor<3072xf32>\n",
      "\t%495=\"ufront.linear\"(%492, %493, %494){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x3072xf32>, tensor<3072xf32>) -> tensor<2x3x3072xf32>\n",
      "\t%496=\"ufront.gelu\"(%495){approximate=true}:(tensor<2x3x3072xf32>) -> tensor<2x3x3072xf32>\n",
      "\t%497=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c250e5331c0\", requires_grad=true}:() -> tensor<3072x768xf32>\n",
      "\t%498=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24d4175670\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%499=\"ufront.linear\"(%496, %497, %498){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x3072xf32>, tensor<3072x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%500=\"ufront.dropout\"(%499){rate=0.1, seed=0, training=false}:(tensor<2x3x768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%501=\"ufront.add\"(%500, %492):(tensor<2x3x768xf32>, tensor<2x3x768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%502=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24cb964860\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%503=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24d9743e30\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%504=\"ufront.layer_norm\"(%501, %502, %503){elementwise_affine=true, eps=0.000000000001, normalized_shape=[768], operand_segment_sizes=array<i32:1, 1, 1>}:(tensor<2x3x768xf32>, tensor<768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%505=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c250ceb3180\", requires_grad=true}:() -> tensor<768x768xf32>\n",
      "\t%506=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24d9745a50\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%507=\"ufront.linear\"(%504, %505, %506){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%508=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c25098b3120\", requires_grad=true}:() -> tensor<768x768xf32>\n",
      "\t%509=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24d9742e20\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%510=\"ufront.linear\"(%504, %508, %509){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%511=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c250d7b31c0\", requires_grad=true}:() -> tensor<768x768xf32>\n",
      "\t%512=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c3fa5550\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%513=\"ufront.linear\"(%504, %511, %512){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%514=\"ufront.reshape\"(%507){shape=[2, 3, 12, 64]}:(tensor<2x3x768xf32>) -> tensor<2x3x12x64xf32>\n",
      "\t%515=\"ufront.transpose\"(%514){perms=[0, 2, 1, 3]}:(tensor<2x3x12x64xf32>) -> tensor<2x12x3x64xf32>\n",
      "\t%516=\"ufront.reshape\"(%510){shape=[2, 3, 12, 64]}:(tensor<2x3x768xf32>) -> tensor<2x3x12x64xf32>\n",
      "\t%517=\"ufront.transpose\"(%516){perms=[0, 2, 1, 3]}:(tensor<2x3x12x64xf32>) -> tensor<2x12x3x64xf32>\n",
      "\t%518=\"ufront.reshape\"(%513){shape=[2, 3, 12, 64]}:(tensor<2x3x768xf32>) -> tensor<2x3x12x64xf32>\n",
      "\t%519=\"ufront.transpose\"(%518){perms=[0, 2, 1, 3]}:(tensor<2x3x12x64xf32>) -> tensor<2x12x3x64xf32>\n",
      "\t%520=\"ufront.transpose\"(%517){perms=[0, 1, 3, 2]}:(tensor<2x12x3x64xf32>) -> tensor<2x12x64x3xf32>\n",
      "\t%521=\"ufront.batch_matmul\"(%515, %520):(tensor<2x12x3x64xf32>, tensor<2x12x64x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%522=\"ufront.struediv\"(%521){scalar=8.0}:(tensor<2x12x3x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%523=\"ufront.add\"(%522, %5):(tensor<2x12x3x3xf32>, tensor<2x1x1x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%524=\"ufront.softmax\"(%523):(tensor<2x12x3x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%525=\"ufront.dropout\"(%524){rate=0.1, seed=0, training=false}:(tensor<2x12x3x3xf32>) -> tensor<2x12x3x3xf32>\n",
      "\t%526=\"ufront.batch_matmul\"(%525, %519):(tensor<2x12x3x3xf32>, tensor<2x12x3x64xf32>) -> tensor<2x12x3x64xf32>\n",
      "\t%527=\"ufront.transpose\"(%526){perms=[0, 2, 1, 3]}:(tensor<2x12x3x64xf32>) -> tensor<2x3x12x64xf32>\n",
      "\t%528=\"ufront.reshape\"(%527){shape=[2, 3, 768]}:(tensor<2x3x12x64xf32>) -> tensor<2x3x768xf32>\n",
      "\t%529=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c250f9731f0\", requires_grad=true}:() -> tensor<768x768xf32>\n",
      "\t%530=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24cb7c20f0\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%531=\"ufront.linear\"(%528, %529, %530){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%532=\"ufront.dropout\"(%531){rate=0.1, seed=0, training=false}:(tensor<2x3x768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%533=\"ufront.add\"(%532, %504):(tensor<2x3x768xf32>, tensor<2x3x768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%534=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24cb7c8000\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%535=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24d3457c20\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%536=\"ufront.layer_norm\"(%533, %534, %535){elementwise_affine=true, eps=0.000000000001, normalized_shape=[768], operand_segment_sizes=array<i32:1, 1, 1>}:(tensor<2x3x768xf32>, tensor<768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%537=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c25116b3230\", requires_grad=true}:() -> tensor<768x3072xf32>\n",
      "\t%538=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c336a6e0\", requires_grad=true}:() -> tensor<3072xf32>\n",
      "\t%539=\"ufront.linear\"(%536, %537, %538){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x768xf32>, tensor<768x3072xf32>, tensor<3072xf32>) -> tensor<2x3x3072xf32>\n",
      "\t%540=\"ufront.gelu\"(%539){approximate=true}:(tensor<2x3x3072xf32>) -> tensor<2x3x3072xf32>\n",
      "\t%541=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c2511fb3240\", requires_grad=true}:() -> tensor<3072x768xf32>\n",
      "\t%542=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c3f29b50\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%543=\"ufront.linear\"(%540, %541, %542){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x3x3072xf32>, tensor<3072x768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%544=\"ufront.dropout\"(%543){rate=0.1, seed=0, training=false}:(tensor<2x3x768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%545=\"ufront.add\"(%544, %536):(tensor<2x3x768xf32>, tensor<2x3x768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%546=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c336e8a0\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%547=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c336fa60\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%548=\"ufront.layer_norm\"(%545, %546, %547){elementwise_affine=true, eps=0.000000000001, normalized_shape=[768], operand_segment_sizes=array<i32:1, 1, 1>}:(tensor<2x3x768xf32>, tensor<768xf32>, tensor<768xf32>) -> tensor<2x3x768xf32>\n",
      "\t%549=\"ufront.slice\"(%548){output_shape=[2, 768], slices=[[0, 2, 1],0]}:(tensor<2x3x768xf32>) -> tensor<2x768xf32>\n",
      "\t%550=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c2510933200\", requires_grad=true}:() -> tensor<768x768xf32>\n",
      "\t%551=\"ufront.parameter\"(){dtype=\"Float\", initializer=\"0x5c24c44f8410\", requires_grad=true}:() -> tensor<768xf32>\n",
      "\t%552=\"ufront.linear\"(%549, %550, %551){operand_segment_sizes=array<i32:1, 1, 1>, weight_transposed=false}:(tensor<2x768xf32>, tensor<768x768xf32>, tensor<768xf32>) -> tensor<2x768xf32>\n",
      "\t%553=\"ufront.tanh\"(%552):(tensor<2x768xf32>) -> tensor<2x768xf32>\n",
      "\treturn %548, %553: tensor<2x3x768xf32>, tensor<2x768xf32>\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(modelir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad961763",
   "metadata": {
    "papermill": {
     "duration": 0.607407,
     "end_time": "2024-05-23T04:41:47.081243",
     "exception": false,
     "start_time": "2024-05-23T04:41:46.473836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 2553087,
     "sourceId": 4336109,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4286.333331,
   "end_time": "2024-05-23T04:41:51.328198",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-23T03:30:24.994867",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
