# UFront
Unified MLIR Frontend for Deep Learning 

## How to reproduce the results
### Option 1 (recommended):

Experiencing UFront on Kaggle (for model compilation, performance comparison, ImageNet inference, accuracy validation, etc.)

Run the anonymous UFront online tests in Kaggle using the links below, **be sure to login** to use full functionality and free GPU (T4x2) resources.

https://www.kaggle.com/code/anomyuser/ufront-test/

https://www.kaggle.com/code/anomyuser/test-torch

https://www.kaggle.com/code/anomyuser/test-tf

**Note**: the results on Kaggle may slightly different from the paper reported because of different CPU and GPU used.

**Important:** Access GPU at no cost or turn on an internet connection. Need to **login** and **Get phone verified** in Kaggle.

**The Internet Connection** in the Kaggle notebook need to be **turned on** to allow package download.

### Option 2 (contains performance comparison on: CPU, RTX 3070, A100):
Execute provided jupyter notebooks in the examples folder, be sure to install dependencies (see following guideline):
```sh
test_tf.ipynb

test_torch.ipynb

test_accuracy.ipynb

```

### Option 3 (suitable for debug):
Execute python scripts, you may install corresponding dependencies manually.

```sh
python examples/torch_test.py
python examples/bert_test.py
python examples/lstm_test.py
python examples/keras_test.py
python examples/onnx_test.py
```


### Option 4

ImageNet inference with UFront locally

1) Download ImageNet validation set (about 2GB, named "imagenet1kvalid") from kaggle.com and extract it to a local folder

2) In the example/test_accuracy.ipynb (jupyter notebook), change the root path to the parent folder of "imagenet1kvalid", execute all notebook cells (depend on your local Python version, you may install different UFront packages).
   

## Examples' dependencies
### Install pre-build ufront package
In Ubuntu 20.04 or 22.04, download corresponding ufront package in the release folder and install.

Install any of the following packages according to your default Python version.
```sh
pip install ufront-0.1.1-cp37-cp37m-manylinux_2_28_x86_64.whl #for Python3.7

pip install ufront-0.1.1-cp38-cp38-manylinux_2_28_x86_64.whl #for Python3.8

pip install ufront-0.1.1-cp39-cp39-manylinux_2_28_x86_64.whl #for Python3.9

pip install ufront-0.1.1-cp310-cp310-manylinux_2_28_x86_64.whl #for Python3.10

pip install ufront-0.1.1-cp311-cp311-manylinux_2_28_x86_64.whl #for Python3.11
```

### Install Execution Backend (IREE)
Recommended stable IREE
```sh
pip install iree-compiler==20230524.529 iree-runtime==20230524.529 
```

If you want to experience new features of Torch-MLIR (under Python 3.11 and CUDA 12), install: 
```sh
pip install iree_compiler==20240129.785 iree_runtime==20240129.785
```

If you want to experience IREE-TF, install:
```sh
pip install iree-compiler==20230815.614 iree-runtime==20230815.614
```

For older Python like Python3.7 you may install previous iree because recent iree release does not provide Python 3.7 support:
```sh
pip install iree-compiler==20230330.474 -f https://github.com/iree-org/iree/releases/download/candidate-20230330.474/iree_compiler-20230330.474-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl

pip iree-runtime==20230330.474 -f https://github.com/iree-org/iree/releases/download/candidate-20230330.474/iree_runtime-20230330.474-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl
```

## Trouble shootings

### 1. CUDA RuntimeError

If you experiencing the following error, you need to upgrade NVidia Driver and CUDA; or you can lower IREE to a lower version, e.g., 20230330.474 (howover, the results may slightly different from reported). The PTX code generated by recent IREE is not compatible with old NVidia Driver.

RuntimeError: Error creating vm context with modules:main_checkout/runtime/src/iree/hal/drivers/cuda/native_executable.c:99: INTERNALï¼›CUDA driver error 'CUDA_ERROR_UNSUPPORTED_PTX_VERSION' (222):the provided PTX was compiled with an unsupported toolchain.;while invoking native function hal.executable.create; while calling import;

### 2. Mismatched IREE and CUDA

For **CUDA 11**, the stable IREE is:
```sh
pip install iree-compiler==20230524.529 iree-runtime==20230524.529 
```

For **CUDA 12**, the compatible IREE are:
Python 3.11
```sh
pip install iree_compiler==20240129.785 iree_runtime==20240129.785
```

Python 3.10
```sh
pip install iree-compiler==20230815.614 iree-runtime==20230815.614
```

However, newer IREE like v20230815.614 has problems for performance bechmark (iree-benchmark-module), the resolution is:

1) Find if iree-benchmark-module available in _runtime_libs folder
```sh
ls /opt/conda/lib/python3.10/site-packages/iree/_runtime_libs/
```
2) Copy it to the runtime folder
```sh
cp /opt/conda/lib/python3.10/site-packages/iree/_runtime_libs/iree-benchmark-module /opt/conda/lib/python3.10/site-packages/iree/runtime/
```

### Torch-MLIR, IREE-TF, ONNX-MLIR
Torch-MLIR is bunded with torch (dev), to compile torch models using Torch-MLIR, you need to download both torch-mlir and torch package from their release website, for example https://github.com/llvm/torch-mlir/releases/tag/snapshot-20240127.1096 The installed torch-mlir also need to be compatible with IREE. Torch-MLIR requires torchvision 0.18.0
```sh
!pip install https://github.com/llvm/torch-mlir/releases/download/snapshot-20240127.1096/torch_mlir-20240127.1096-cp311-cp311-linux_x86_64.whl --no-dependencies
!pip install https://github.com/llvm/torch-mlir/releases/download/snapshot-20240127.1096/torch-2.3.0.dev20240122+cpu-cp311-cp311-linux_x86_64.whl --no-dependencies
!pip install https://download.pytorch.org/whl/cpu/torchvision-0.18.0%2Bcpu-cp311-cp311-linux_x86_64.whl --no-dependencies
```

The compatible IREE backend for recent torch-mlir release (Python 3.11 environment) is:
```sh
!pip install iree_compiler==20240129.785 iree_runtime==20240129.785
```

If you are using Python 3.9, Python 3.10 or previous torch-mlir release, you may use previous IREE backend:
```sh
!pip install iree-compiler==20230815.614 iree-runtime==20230815.614
```
```sh
!pip install iree-compiler==20230524.529 iree-runtime==20230524.529
```

IREE-TF and some Tensorflow models has the following dependencies
```sh
pip uninstall tensorflow -y
pip install tensorflow-cpu==2.13.0
pip install tensorflow-addons==0.21.0
pip install validators
pip install scipy
pip install opencv-python
apt install libgl1 -y
```

The compatible IREE backend for tensorflow 2.13, 2.14 and 2.15 is:
```sh
pip install iree-compiler==20230815.614 iree-runtime==20230815.614
```
```sh
pip install iree-compiler==20230524.529 iree-runtime==20230524.529
```

If you encouter problems for compiling models using IREE-TF, you may install the IREE-TF tools and other versions of iree-runtime:
```sh
pip install iree-tools-tf==20230524.529  iree-tools-tflite==20230524.529

# Python 3.9
pip install https://github.com/iree-org/iree/releases/download/candidate-20230816.615/iree_runtime-20230816.615-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl

# Python 3.10
pip https://github.com/iree-org/iree/releases/download/candidate-20230816.615/iree_runtime-20230816.615-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl

# Python 3.11
pip install https://github.com/iree-org/iree/releases/download/candidate-20230816.615/iree_runtime-20230816.615-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl
```

ONNX-MLIR on GPU? No official support yet.





